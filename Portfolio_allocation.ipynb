{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BU12z_ebVPsE"
   },
   "source": [
    "# Global configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JHFmX8bTVc4W",
    "outputId": "07ef89bf-538f-4e92-888a-807d176ec0c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.1.69-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: pandas>=0.24 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from yfinance) (1.2.4)\n",
      "Collecting requests>=2.26\n",
      "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 212 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multitasking>=0.0.7\n",
      "  Downloading multitasking-0.0.10.tar.gz (8.2 kB)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from yfinance) (1.19.5)\n",
      "Requirement already satisfied: lxml>=4.5.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from yfinance) (4.6.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=0.24->yfinance) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests>=2.26->yfinance) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests>=2.26->yfinance) (2.10)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.10-py3-none-any.whl (39 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests>=2.26->yfinance) (1.26.4)\n",
      "Building wheels for collected packages: multitasking\n",
      "  Building wheel for multitasking (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for multitasking: filename=multitasking-0.0.10-py3-none-any.whl size=8488 sha256=0259faaf757fb3246cd02a233e7213759e0d7b928ff1d0530ac19866d01e6988\n",
      "  Stored in directory: /Users/liupeng/Library/Caches/pip/wheels/34/ba/79/c0260c6f1a03f420ec7673eff9981778f293b9107974679e36\n",
      "Successfully built multitasking\n",
      "Installing collected packages: charset-normalizer, requests, multitasking, yfinance\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.25.1\n",
      "    Uninstalling requests-2.25.1:\n",
      "      Successfully uninstalled requests-2.25.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "apache-beam 2.29.0 requires typing-extensions<3.8.0,>=3.7.0, but you have typing-extensions 4.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed charset-normalizer-2.0.10 multitasking-0.0.10 requests-2.27.1 yfinance-0.1.69\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "import torch\n",
    "import random\n",
    "SEED=8\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9glaZw4xV4NK"
   },
   "outputs": [],
   "source": [
    "# check https://wrds-www.wharton.upenn.edu/ for U.S. index constituents\n",
    "# Dow 30 constituents in 2021/10\n",
    "DOW_30_TICKER = [\"AXP\", \"AMGN\", \"AAPL\", \"BA\", \"CAT\", \"CSCO\", \"CVX\", \"GS\", \"HD\",\n",
    "                 \"HON\", \"IBM\", \"INTC\", \"JNJ\", \"KO\", \"JPM\", \"MCD\", \"MMM\", \"MRK\",\n",
    "                 \"MSFT\", \"NKE\", \"PG\", \"TRV\", \"UNH\", \"CRM\", \"VZ\", \"V\", \"WBA\", \n",
    "                 \"WMT\", \"DIS\", \"DOW\"]\n",
    "## stockstats technical indicator column names\n",
    "## check https://pypi.org/project/stockstats/ for different names\n",
    "TECHNICAL_INDICATORS_LIST = [\"macd\", \"boll_ub\", \"boll_lb\", \"rsi_30\", \"cci_30\",\n",
    "                             \"dx_30\", \"close_30_sma\", \"close_60_sma\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31homrqTcCUI"
   },
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pog4MLmxbzPN"
   },
   "outputs": [],
   "source": [
    "class YahooFinanceProcessor:\n",
    "    \"\"\"Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from neofinrl_config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from neofinrl_config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from neofinrl_config.py)\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def download_data(\n",
    "        self, start_date: str, end_date: str, ticker_list: list, time_interval: str\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Fetches data from Yahoo API\n",
    "        Parameters\n",
    "        ----------\n",
    "        Returns\n",
    "        -------\n",
    "        `pd.DataFrame`\n",
    "            7 columns: A date, open, high, low, close, volume and tick symbol\n",
    "            for the specified stock ticker\n",
    "        \"\"\"\n",
    "\n",
    "        self.start = start_date\n",
    "        self.end = end_date\n",
    "        self.time_interval = time_interval\n",
    "\n",
    "        # Download and save the data in a pandas DataFrame:\n",
    "        data_df = pd.DataFrame()\n",
    "        for tic in ticker_list:\n",
    "            temp_df = yf.download(tic, start=start_date, end=end_date)\n",
    "            temp_df[\"tic\"] = tic\n",
    "            data_df = data_df.append(temp_df)\n",
    "        # reset the index, we want to use numbers as index instead of dates\n",
    "        data_df = data_df.reset_index()\n",
    "        try:\n",
    "            # convert the column names to standardized names\n",
    "            data_df.columns = [\n",
    "                \"date\",\n",
    "                \"open\",\n",
    "                \"high\",\n",
    "                \"low\",\n",
    "                \"close\",\n",
    "                \"adjcp\",\n",
    "                \"volume\",\n",
    "                \"tic\",\n",
    "            ]\n",
    "        except NotImplementedError:\n",
    "            print(\"the features are not supported currently\")\n",
    "        # create day of the week column (monday = 0)\n",
    "        data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
    "        # convert date to standard string format, easy to filter\n",
    "        data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
    "        # drop missing data\n",
    "        data_df = data_df.dropna()\n",
    "        data_df = data_df.reset_index(drop=True)\n",
    "        print(\"Shape of DataFrame: \", data_df.shape)\n",
    "        # print(\"Display DataFrame: \", data_df.head())\n",
    "\n",
    "        data_df = data_df.sort_values(by=[\"date\", \"tic\"]).reset_index(drop=True)\n",
    "\n",
    "        return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DX_EgnaPb8VK",
    "outputId": "9fe3fc3e-caf9-4860-9deb-d78440dcb624"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Shape of DataFrame:  (101643, 9)\n"
     ]
    }
   ],
   "source": [
    "dp = YahooFinanceProcessor()\n",
    "df = dp.download_data(start_date = '2008-01-01',\n",
    "                     end_date = '2021-10-31',\n",
    "                     ticker_list = DOW_30_TICKER, time_interval='1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JOiHiVhSdFLr",
    "outputId": "79034d9a-bb68-4ee5-89b6-d60d83977146"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>7.160714</td>\n",
       "      <td>7.062500</td>\n",
       "      <td>7.074286</td>\n",
       "      <td>6.065245</td>\n",
       "      <td>539333200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>46.840000</td>\n",
       "      <td>46.880001</td>\n",
       "      <td>46.209999</td>\n",
       "      <td>46.439999</td>\n",
       "      <td>35.911190</td>\n",
       "      <td>7226000</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>50.849998</td>\n",
       "      <td>52.570000</td>\n",
       "      <td>50.619999</td>\n",
       "      <td>52.020000</td>\n",
       "      <td>41.228928</td>\n",
       "      <td>8380600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>88.139999</td>\n",
       "      <td>88.279999</td>\n",
       "      <td>87.239998</td>\n",
       "      <td>87.459999</td>\n",
       "      <td>64.097214</td>\n",
       "      <td>3184200</td>\n",
       "      <td>BA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.709999</td>\n",
       "      <td>72.389999</td>\n",
       "      <td>72.559998</td>\n",
       "      <td>48.934669</td>\n",
       "      <td>2639600</td>\n",
       "      <td>CAT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close      adjcp  \\\n",
       "0  2007-12-31   7.125000   7.160714   7.062500   7.074286   6.065245   \n",
       "1  2007-12-31  46.840000  46.880001  46.209999  46.439999  35.911190   \n",
       "2  2007-12-31  50.849998  52.570000  50.619999  52.020000  41.228928   \n",
       "3  2007-12-31  88.139999  88.279999  87.239998  87.459999  64.097214   \n",
       "4  2007-12-31  73.000000  73.709999  72.389999  72.559998  48.934669   \n",
       "\n",
       "      volume   tic  day  \n",
       "0  539333200  AAPL    0  \n",
       "1    7226000  AMGN    0  \n",
       "2    8380600   AXP    0  \n",
       "3    3184200    BA    0  \n",
       "4    2639600   CAT    0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilfG9sNPdjoh",
    "outputId": "cbf53064-c0eb-47c3-83a6-5caf15ee762d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101643, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edYaOxxfXsvP"
   },
   "source": [
    "# Add technical indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_JtcIvYedu46",
    "outputId": "93bc7071-8133-4a9c-c503-b756ef5a74c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stockstats\n",
      "  Downloading stockstats-0.4.1-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stockstats) (1.2.4)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=0.24.2->stockstats) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=0.24.2->stockstats) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas>=0.24.2->stockstats) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->stockstats) (1.15.0)\n",
      "Installing collected packages: stockstats\n",
      "Successfully installed stockstats-0.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install stockstats\n",
    "from stockstats import StockDataFrame as Sdf\n",
    "class FeatureEngineer:\n",
    "    \"\"\"Provides methods for preprocessing the stock price data\n",
    "    Attributes\n",
    "    ----------\n",
    "        use_technical_indicator : boolean\n",
    "            we technical indicator or not\n",
    "        tech_indicator_list : list\n",
    "            a list of technical indicator names (modified from neofinrl_config.py)\n",
    "        use_turbulence : boolean\n",
    "            use turbulence index or not\n",
    "        user_defined_feature:boolean\n",
    "            user user defined features or not\n",
    "    Methods\n",
    "    -------\n",
    "    preprocess_data()\n",
    "        main method to do the feature engineering\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        use_technical_indicator=True,\n",
    "        tech_indicator_list=TECHNICAL_INDICATORS_LIST,\n",
    "        use_vix=False,\n",
    "        use_turbulence=False,\n",
    "        user_defined_feature=False,\n",
    "    ):\n",
    "        self.use_technical_indicator = use_technical_indicator\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "        self.use_vix = use_vix\n",
    "        self.use_turbulence = use_turbulence\n",
    "        self.user_defined_feature = user_defined_feature\n",
    "\n",
    "    def preprocess_data(self, df):\n",
    "        \"\"\"main method to do the feature engineering\n",
    "        @:param config: source dataframe\n",
    "        @:return: a DataMatrices object\n",
    "        \"\"\"\n",
    "        # clean data\n",
    "        df = self.clean_data(df)\n",
    "\n",
    "        # add technical indicators using stockstats\n",
    "        if self.use_technical_indicator:\n",
    "            df = self.add_technical_indicator(df)\n",
    "            print(\"Successfully added technical indicators\")\n",
    "\n",
    "        # add vix for multiple stock\n",
    "        if self.use_vix:\n",
    "            df = self.add_vix(df)\n",
    "            print(\"Successfully added vix\")\n",
    "\n",
    "        # add turbulence index for multiple stock\n",
    "        if self.use_turbulence:\n",
    "            df = self.add_turbulence(df)\n",
    "            print(\"Successfully added turbulence index\")\n",
    "\n",
    "        # add user defined feature\n",
    "        if self.user_defined_feature:\n",
    "            df = self.add_user_defined_feature(df)\n",
    "            print(\"Successfully added user defined features\")\n",
    "\n",
    "        # fill the missing values at the beginning and the end\n",
    "        df = df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        return df\n",
    "\n",
    "    def clean_data(self, data):\n",
    "        \"\"\"\n",
    "        clean the raw data\n",
    "        deal with missing values\n",
    "        reasons: stocks could be delisted, not incorporated at the time step\n",
    "        :param data: (df) pandas dataframe\n",
    "        :return: (df) pandas dataframe\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "        df = df.sort_values([\"date\", \"tic\"], ignore_index=True)\n",
    "        df.index = df.date.factorize()[0]\n",
    "        merged_closes = df.pivot_table(index=\"date\", columns=\"tic\", values=\"close\")\n",
    "        merged_closes = merged_closes.dropna(axis=1)\n",
    "        tics = merged_closes.columns\n",
    "        df = df[df.tic.isin(tics)]\n",
    "        # df = data.copy()\n",
    "        # list_ticker = df[\"tic\"].unique().tolist()\n",
    "        # only apply to daily level data, need to fix for minute level\n",
    "        # list_date = list(pd.date_range(df['date'].min(),df['date'].max()).astype(str))\n",
    "        # combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "        # df_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(df,on=[\"date\",\"tic\"],how=\"left\")\n",
    "        # df_full = df_full[df_full['date'].isin(df['date'])]\n",
    "        # df_full = df_full.sort_values(['date','tic'])\n",
    "        # df_full = df_full.fillna(0)\n",
    "        return df\n",
    "\n",
    "    def add_technical_indicator(self, data):\n",
    "        \"\"\"\n",
    "        calculate technical indicators\n",
    "        use stockstats package to add technical inidactors\n",
    "        :param data: (df) pandas dataframe\n",
    "        :return: (df) pandas dataframe\n",
    "        \"\"\"\n",
    "        df = data.copy()\n",
    "        df = df.sort_values(by=[\"tic\", \"date\"])\n",
    "        stock = Sdf.retype(df.copy())\n",
    "        unique_ticker = stock.tic.unique()\n",
    "\n",
    "        for indicator in self.tech_indicator_list:\n",
    "            indicator_df = pd.DataFrame()\n",
    "            for i in range(len(unique_ticker)):\n",
    "                try:\n",
    "                    temp_indicator = stock[stock.tic == unique_ticker[i]][indicator]\n",
    "                    temp_indicator = pd.DataFrame(temp_indicator)\n",
    "                    temp_indicator[\"tic\"] = unique_ticker[i]\n",
    "                    temp_indicator[\"date\"] = df[df.tic == unique_ticker[i]][\n",
    "                        \"date\"\n",
    "                    ].to_list()\n",
    "                    indicator_df = indicator_df.append(\n",
    "                        temp_indicator, ignore_index=True\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "            df = df.merge(\n",
    "                indicator_df[[\"tic\", \"date\", indicator]], on=[\"tic\", \"date\"], how=\"left\"\n",
    "            )\n",
    "        df = df.sort_values(by=[\"date\", \"tic\"])\n",
    "        return df\n",
    "        # df = data.set_index(['date','tic']).sort_index()\n",
    "        # df = df.join(df.groupby(level=0, group_keys=False).apply(lambda x, y: Sdf.retype(x)[y], y=self.tech_indicator_list))\n",
    "        # return df.reset_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jdq4SuoilQvj",
    "outputId": "befee03f-f498-4b02-a4cb-72ab03b206b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    use_turbulence=False,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "df = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2Vp8fK9l60Z",
    "outputId": "6d1a6213-a173-4c7f-9722-04cbb8717ef9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97552, 17)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "H2sC3EVvoQli",
    "outputId": "9db4a48e-bb6e-4e90-d47a-a420068f262b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>7.160714</td>\n",
       "      <td>7.062500</td>\n",
       "      <td>7.074286</td>\n",
       "      <td>6.065245</td>\n",
       "      <td>539333200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.180074</td>\n",
       "      <td>6.852783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>7.074286</td>\n",
       "      <td>7.074286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>46.840000</td>\n",
       "      <td>46.880001</td>\n",
       "      <td>46.209999</td>\n",
       "      <td>46.439999</td>\n",
       "      <td>35.911190</td>\n",
       "      <td>7226000</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.180074</td>\n",
       "      <td>6.852783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>46.439999</td>\n",
       "      <td>46.439999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6968</th>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>50.849998</td>\n",
       "      <td>52.570000</td>\n",
       "      <td>50.619999</td>\n",
       "      <td>52.020000</td>\n",
       "      <td>41.228928</td>\n",
       "      <td>8380600</td>\n",
       "      <td>AXP</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.180074</td>\n",
       "      <td>6.852783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>52.020000</td>\n",
       "      <td>52.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10452</th>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>88.139999</td>\n",
       "      <td>88.279999</td>\n",
       "      <td>87.239998</td>\n",
       "      <td>87.459999</td>\n",
       "      <td>64.097214</td>\n",
       "      <td>3184200</td>\n",
       "      <td>BA</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.180074</td>\n",
       "      <td>6.852783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>87.459999</td>\n",
       "      <td>87.459999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13936</th>\n",
       "      <td>2007-12-31</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>73.709999</td>\n",
       "      <td>72.389999</td>\n",
       "      <td>72.559998</td>\n",
       "      <td>48.934669</td>\n",
       "      <td>2639600</td>\n",
       "      <td>CAT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.180074</td>\n",
       "      <td>6.852783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.559998</td>\n",
       "      <td>72.559998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date       open       high        low      close      adjcp  \\\n",
       "0      2007-12-31   7.125000   7.160714   7.062500   7.074286   6.065245   \n",
       "3484   2007-12-31  46.840000  46.880001  46.209999  46.439999  35.911190   \n",
       "6968   2007-12-31  50.849998  52.570000  50.619999  52.020000  41.228928   \n",
       "10452  2007-12-31  88.139999  88.279999  87.239998  87.459999  64.097214   \n",
       "13936  2007-12-31  73.000000  73.709999  72.389999  72.559998  48.934669   \n",
       "\n",
       "          volume   tic  day  macd   boll_ub   boll_lb  rsi_30     cci_30  \\\n",
       "0      539333200  AAPL    0   0.0  7.180074  6.852783     0.0 -66.666667   \n",
       "3484     7226000  AMGN    0   0.0  7.180074  6.852783     0.0 -66.666667   \n",
       "6968     8380600   AXP    0   0.0  7.180074  6.852783     0.0 -66.666667   \n",
       "10452    3184200    BA    0   0.0  7.180074  6.852783     0.0 -66.666667   \n",
       "13936    2639600   CAT    0   0.0  7.180074  6.852783     0.0 -66.666667   \n",
       "\n",
       "       dx_30  close_30_sma  close_60_sma  \n",
       "0      100.0      7.074286      7.074286  \n",
       "3484   100.0     46.439999     46.439999  \n",
       "6968   100.0     52.020000     52.020000  \n",
       "10452  100.0     87.459999     87.459999  \n",
       "13936  100.0     72.559998     72.559998  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "989PHnDLX3uK"
   },
   "source": [
    "# Add covariance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e5iLVSKhoUEy"
   },
   "outputs": [],
   "source": [
    "# add covariance matrix as states\n",
    "df=df.sort_values(['date','tic'],ignore_index=True)\n",
    "df.index = df.date.factorize()[0]\n",
    "\n",
    "cov_list = []\n",
    "return_list = []\n",
    "\n",
    "# look back is one year\n",
    "lookback=252\n",
    "for i in range(lookback,len(df.index.unique())):\n",
    "  data_lookback = df.loc[i-lookback:i,:]\n",
    "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
    "  return_lookback = price_lookback.pct_change().dropna()\n",
    "  return_list.append(return_lookback)\n",
    "\n",
    "  covs = return_lookback.cov().values \n",
    "  cov_list.append(covs)\n",
    "\n",
    "  \n",
    "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
    "df = df.merge(df_cov, on='date')\n",
    "df = df.sort_values(['date','tic']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JIG2p4uNZoUh",
    "outputId": "8f64b598-fef7-4a2e-c1be-5e00e0e26360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90496, 19)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "8e11UpDrZow2",
    "outputId": "adf6fcd9-b151-4109-bfef-910d6c569022"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-30</td>\n",
       "      <td>3.122143</td>\n",
       "      <td>3.144643</td>\n",
       "      <td>3.025714</td>\n",
       "      <td>3.081786</td>\n",
       "      <td>2.642215</td>\n",
       "      <td>967601600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.095139</td>\n",
       "      <td>3.647287</td>\n",
       "      <td>2.922999</td>\n",
       "      <td>42.673739</td>\n",
       "      <td>-80.272843</td>\n",
       "      <td>16.129793</td>\n",
       "      <td>3.246952</td>\n",
       "      <td>3.383500</td>\n",
       "      <td>[[0.0013494488623757655, 0.0004283422043926854...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-30</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>57.660000</td>\n",
       "      <td>56.820000</td>\n",
       "      <td>57.590000</td>\n",
       "      <td>44.533279</td>\n",
       "      <td>4300800</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.206630</td>\n",
       "      <td>59.373659</td>\n",
       "      <td>55.651341</td>\n",
       "      <td>50.840501</td>\n",
       "      <td>37.623751</td>\n",
       "      <td>17.245628</td>\n",
       "      <td>56.616000</td>\n",
       "      <td>55.998167</td>\n",
       "      <td>[[0.0013494488623757655, 0.0004283422043926854...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-30</td>\n",
       "      <td>17.820000</td>\n",
       "      <td>18.129999</td>\n",
       "      <td>17.700001</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>14.507501</td>\n",
       "      <td>11777300</td>\n",
       "      <td>AXP</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.263168</td>\n",
       "      <td>23.794809</td>\n",
       "      <td>16.256191</td>\n",
       "      <td>41.524298</td>\n",
       "      <td>-101.263980</td>\n",
       "      <td>33.966523</td>\n",
       "      <td>20.057333</td>\n",
       "      <td>22.604000</td>\n",
       "      <td>[[0.0013494488623757655, 0.0004283422043926854...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-30</td>\n",
       "      <td>40.080002</td>\n",
       "      <td>41.340000</td>\n",
       "      <td>39.810001</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>30.940769</td>\n",
       "      <td>4549700</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.597202</td>\n",
       "      <td>42.590111</td>\n",
       "      <td>38.593890</td>\n",
       "      <td>45.299685</td>\n",
       "      <td>38.696627</td>\n",
       "      <td>7.693500</td>\n",
       "      <td>40.382334</td>\n",
       "      <td>43.448167</td>\n",
       "      <td>[[0.0013494488623757655, 0.0004283422043926854...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-30</td>\n",
       "      <td>42.570000</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>42.009998</td>\n",
       "      <td>43.660000</td>\n",
       "      <td>30.225826</td>\n",
       "      <td>5060400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "      <td>0.850860</td>\n",
       "      <td>45.671279</td>\n",
       "      <td>37.851721</td>\n",
       "      <td>49.916105</td>\n",
       "      <td>73.697581</td>\n",
       "      <td>19.456481</td>\n",
       "      <td>39.967000</td>\n",
       "      <td>39.993833</td>\n",
       "      <td>[[0.0013494488623757655, 0.0004283422043926854...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close      adjcp  \\\n",
       "0  2008-12-30   3.122143   3.144643   3.025714   3.081786   2.642215   \n",
       "1  2008-12-30  57.000000  57.660000  56.820000  57.590000  44.533279   \n",
       "2  2008-12-30  17.820000  18.129999  17.700001  18.000000  14.507501   \n",
       "3  2008-12-30  40.080002  41.340000  39.810001  41.250000  30.940769   \n",
       "4  2008-12-30  42.570000  43.750000  42.009998  43.660000  30.225826   \n",
       "\n",
       "      volume   tic  day      macd    boll_ub    boll_lb     rsi_30  \\\n",
       "0  967601600  AAPL    1 -0.095139   3.647287   2.922999  42.673739   \n",
       "1    4300800  AMGN    1  0.206630  59.373659  55.651341  50.840501   \n",
       "2   11777300   AXP    1 -1.263168  23.794809  16.256191  41.524298   \n",
       "3    4549700    BA    1 -0.597202  42.590111  38.593890  45.299685   \n",
       "4    5060400   CAT    1  0.850860  45.671279  37.851721  49.916105   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
       "0  -80.272843  16.129793      3.246952      3.383500   \n",
       "1   37.623751  17.245628     56.616000     55.998167   \n",
       "2 -101.263980  33.966523     20.057333     22.604000   \n",
       "3   38.696627   7.693500     40.382334     43.448167   \n",
       "4   73.697581  19.456481     39.967000     39.993833   \n",
       "\n",
       "                                            cov_list  \\\n",
       "0  [[0.0013494488623757655, 0.0004283422043926854...   \n",
       "1  [[0.0013494488623757655, 0.0004283422043926854...   \n",
       "2  [[0.0013494488623757655, 0.0004283422043926854...   \n",
       "3  [[0.0013494488623757655, 0.0004283422043926854...   \n",
       "4  [[0.0013494488623757655, 0.0004283422043926854...   \n",
       "\n",
       "                                         return_list  \n",
       "0  tic             AAPL      AMGN       AXP      ...  \n",
       "1  tic             AAPL      AMGN       AXP      ...  \n",
       "2  tic             AAPL      AMGN       AXP      ...  \n",
       "3  tic             AAPL      AMGN       AXP      ...  \n",
       "4  tic             AAPL      AMGN       AXP      ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "JBapGpslbCti"
   },
   "outputs": [],
   "source": [
    "def data_split(df, start, end, target_date_col=\"date\"):\n",
    "    \"\"\"\n",
    "    split the dataset into training or testing using date\n",
    "    :param data: (df) pandas dataframe, start, end\n",
    "    :return: (df) pandas dataframe\n",
    "    \"\"\"\n",
    "    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n",
    "    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n",
    "    data.index = data[target_date_col].factorize()[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "iyQiGwkoZsBc"
   },
   "outputs": [],
   "source": [
    "train = data_split(df, '2009-01-01','2020-07-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "0c4fa76dalGH",
    "outputId": "550bf823-9802-483f-eb70-071ebc540485"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjcp</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>cov_list</th>\n",
       "      <th>return_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>3.067143</td>\n",
       "      <td>3.251429</td>\n",
       "      <td>3.041429</td>\n",
       "      <td>3.241071</td>\n",
       "      <td>2.778781</td>\n",
       "      <td>746015200</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.082758</td>\n",
       "      <td>3.633600</td>\n",
       "      <td>2.892864</td>\n",
       "      <td>45.439909</td>\n",
       "      <td>-30.508777</td>\n",
       "      <td>2.140065</td>\n",
       "      <td>3.244631</td>\n",
       "      <td>3.376833</td>\n",
       "      <td>[[0.001366150662406761, 0.000433938195725591, ...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>58.590000</td>\n",
       "      <td>59.080002</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>58.990002</td>\n",
       "      <td>45.615871</td>\n",
       "      <td>6547900</td>\n",
       "      <td>AMGN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.320448</td>\n",
       "      <td>59.148360</td>\n",
       "      <td>56.339640</td>\n",
       "      <td>52.756899</td>\n",
       "      <td>94.549630</td>\n",
       "      <td>0.814217</td>\n",
       "      <td>56.759667</td>\n",
       "      <td>56.166000</td>\n",
       "      <td>[[0.001366150662406761, 0.000433938195725591, ...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>19.520000</td>\n",
       "      <td>18.400000</td>\n",
       "      <td>19.330000</td>\n",
       "      <td>15.579440</td>\n",
       "      <td>10955700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.059847</td>\n",
       "      <td>23.489423</td>\n",
       "      <td>16.086577</td>\n",
       "      <td>43.923069</td>\n",
       "      <td>-42.018825</td>\n",
       "      <td>16.335101</td>\n",
       "      <td>20.028333</td>\n",
       "      <td>22.263333</td>\n",
       "      <td>[[0.001366150662406761, 0.000433938195725591, ...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>42.799999</td>\n",
       "      <td>45.560001</td>\n",
       "      <td>42.779999</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>33.941090</td>\n",
       "      <td>7010200</td>\n",
       "      <td>BA</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.019566</td>\n",
       "      <td>43.926849</td>\n",
       "      <td>37.932151</td>\n",
       "      <td>50.664491</td>\n",
       "      <td>275.696308</td>\n",
       "      <td>20.494464</td>\n",
       "      <td>40.621667</td>\n",
       "      <td>43.237334</td>\n",
       "      <td>[[0.001366150662406761, 0.000433938195725591, ...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-02</td>\n",
       "      <td>44.910000</td>\n",
       "      <td>46.980000</td>\n",
       "      <td>44.709999</td>\n",
       "      <td>46.910000</td>\n",
       "      <td>32.475788</td>\n",
       "      <td>7117200</td>\n",
       "      <td>CAT</td>\n",
       "      <td>4</td>\n",
       "      <td>1.248426</td>\n",
       "      <td>46.543072</td>\n",
       "      <td>38.372928</td>\n",
       "      <td>53.534306</td>\n",
       "      <td>131.675975</td>\n",
       "      <td>34.637447</td>\n",
       "      <td>40.623333</td>\n",
       "      <td>39.911333</td>\n",
       "      <td>[[0.001366150662406761, 0.000433938195725591, ...</td>\n",
       "      <td>tic             AAPL      AMGN       AXP      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       open       high        low      close      adjcp  \\\n",
       "0  2009-01-02   3.067143   3.251429   3.041429   3.241071   2.778781   \n",
       "0  2009-01-02  58.590000  59.080002  57.750000  58.990002  45.615871   \n",
       "0  2009-01-02  18.570000  19.520000  18.400000  19.330000  15.579440   \n",
       "0  2009-01-02  42.799999  45.560001  42.779999  45.250000  33.941090   \n",
       "0  2009-01-02  44.910000  46.980000  44.709999  46.910000  32.475788   \n",
       "\n",
       "      volume   tic  day      macd    boll_ub    boll_lb     rsi_30  \\\n",
       "0  746015200  AAPL    4 -0.082758   3.633600   2.892864  45.439909   \n",
       "0    6547900  AMGN    4  0.320448  59.148360  56.339640  52.756899   \n",
       "0   10955700   AXP    4 -1.059847  23.489423  16.086577  43.923069   \n",
       "0    7010200    BA    4 -0.019566  43.926849  37.932151  50.664491   \n",
       "0    7117200   CAT    4  1.248426  46.543072  38.372928  53.534306   \n",
       "\n",
       "       cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
       "0  -30.508777   2.140065      3.244631      3.376833   \n",
       "0   94.549630   0.814217     56.759667     56.166000   \n",
       "0  -42.018825  16.335101     20.028333     22.263333   \n",
       "0  275.696308  20.494464     40.621667     43.237334   \n",
       "0  131.675975  34.637447     40.623333     39.911333   \n",
       "\n",
       "                                            cov_list  \\\n",
       "0  [[0.001366150662406761, 0.000433938195725591, ...   \n",
       "0  [[0.001366150662406761, 0.000433938195725591, ...   \n",
       "0  [[0.001366150662406761, 0.000433938195725591, ...   \n",
       "0  [[0.001366150662406761, 0.000433938195725591, ...   \n",
       "0  [[0.001366150662406761, 0.000433938195725591, ...   \n",
       "\n",
       "                                         return_list  \n",
       "0  tic             AAPL      AMGN       AXP      ...  \n",
       "0  tic             AAPL      AMGN       AXP      ...  \n",
       "0  tic             AAPL      AMGN       AXP      ...  \n",
       "0  tic             AAPL      AMGN       AXP      ...  \n",
       "0  tic             AAPL      AMGN       AXP      ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfC-0ZEVbZp8"
   },
   "source": [
    "# Design Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zhtc1plbSQB",
    "outputId": "4d3165df-f035-42b6-c429-f44dcd03b59c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (1.3.0)\n",
      "Requirement already satisfied: pandas in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (1.2.4)\n",
      "Requirement already satisfied: cloudpickle in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (1.6.0)\n",
      "Requirement already satisfied: matplotlib in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (3.2.2)\n",
      "Requirement already satisfied: torch>=1.8.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: numpy in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (1.19.5)\n",
      "Requirement already satisfied: gym<0.20,>=0.17 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (0.18.0)\n",
      "Requirement already satisfied: psutil in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (5.8.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (2.5.0)\n",
      "Requirement already satisfied: atari-py~=0.2.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (0.2.9)\n",
      "Requirement already satisfied: opencv-python in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (4.5.2.52)\n",
      "Requirement already satisfied: pillow in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from stable-baselines3[extra]) (8.2.0)\n",
      "Requirement already satisfied: six in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from atari-py~=0.2.0->stable-baselines3[extra]) (1.15.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.12.3)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.12.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.34.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (3.3.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.36.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.30.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (52.0.0.post20210125)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from tensorboard>=2.2.0->stable-baselines3[extra]) (1.8.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->stable-baselines3[extra]) (4.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->stable-baselines3[extra]) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from torch>=1.8.1->stable-baselines3[extra]) (4.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.2.0->stable-baselines3[extra]) (3.4.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas->stable-baselines3[extra]) (2021.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym.utils import seeding\n",
    "import gym\n",
    "from gym import spaces\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "\n",
    "class StockPortfolioEnv(gym.Env):\n",
    "    \"\"\"A single stock trading environment for OpenAI gym\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        df: DataFrame\n",
    "            input data\n",
    "        stock_dim : int\n",
    "            number of unique stocks\n",
    "        hmax : int\n",
    "            maximum number of shares to trade\n",
    "        initial_amount : int\n",
    "            start money\n",
    "        transaction_cost_pct: float\n",
    "            transaction cost percentage per trade\n",
    "        reward_scaling: float\n",
    "            scaling factor for reward, good for training\n",
    "        state_space: int\n",
    "            the dimension of input features\n",
    "        action_space: int\n",
    "            equals stock dimension\n",
    "        tech_indicator_list: list\n",
    "            a list of technical indicator names\n",
    "        turbulence_threshold: int\n",
    "            a threshold to control risk aversion\n",
    "        day: int\n",
    "            an increment number to control date\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    _sell_stock()\n",
    "        perform sell action based on the sign of the action\n",
    "    _buy_stock()\n",
    "        perform buy action based on the sign of the action\n",
    "    step()\n",
    "        at each step the agent will return actions, then \n",
    "        we will calculate the reward, and return the next observation.\n",
    "    reset()\n",
    "        reset the environment\n",
    "    render()\n",
    "        use render to return other functions\n",
    "    save_asset_memory()\n",
    "        return account value at each time step\n",
    "    save_action_memory()\n",
    "        return actions/positions at each time step\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    metadata = {'render.modes': ['human']}\n",
    "\n",
    "    def __init__(self, \n",
    "                df,\n",
    "                stock_dim,\n",
    "                hmax,\n",
    "                initial_amount,\n",
    "                transaction_cost_pct,\n",
    "                reward_scaling,\n",
    "                state_space,\n",
    "                action_space,\n",
    "                tech_indicator_list,\n",
    "                turbulence_threshold=None,\n",
    "                lookback=252,\n",
    "                day = 0):\n",
    "        #super(StockEnv, self).__init__()\n",
    "        #money = 10 , scope = 1\n",
    "        self.day = day\n",
    "        self.lookback=lookback\n",
    "        self.df = df\n",
    "        self.stock_dim = stock_dim\n",
    "        self.hmax = hmax\n",
    "        self.initial_amount = initial_amount\n",
    "        self.transaction_cost_pct =transaction_cost_pct\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.state_space = state_space\n",
    "        self.action_space = action_space\n",
    "        self.tech_indicator_list = tech_indicator_list\n",
    "\n",
    "        # action_space normalization and shape is self.stock_dim\n",
    "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,)) \n",
    "        # Shape = (34, 30)\n",
    "        # covariance matrix + technical indicators\n",
    "        # self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space+len(self.tech_indicator_list),self.state_space))\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = ((self.state_space+len(self.tech_indicator_list)) * self.state_space,))\n",
    "        self.feat_dim = self.state_space+len(self.tech_indicator_list)\n",
    "\n",
    "        # load data from a pandas dataframe\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "        self.state = self.state.ravel()\n",
    "        self.terminal = False     \n",
    "        self.turbulence_threshold = turbulence_threshold        \n",
    "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
    "        self.portfolio_value = self.initial_amount\n",
    "\n",
    "        # memorize portfolio value each step\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        # memorize portfolio return each step\n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]]\n",
    "\n",
    "        \n",
    "    def step(self, actions):\n",
    "        # print(self.day)\n",
    "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
    "        # print(actions)\n",
    "\n",
    "        if self.terminal:\n",
    "            df = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df.columns = ['daily_return']\n",
    "            plt.plot(df.daily_return.cumsum(),'r')\n",
    "            plt.savefig('cumulative_reward.png')\n",
    "            plt.close()\n",
    "            \n",
    "            plt.plot(self.portfolio_return_memory,'r')\n",
    "            plt.savefig('rewards.png')\n",
    "            plt.close()\n",
    "\n",
    "            print(\"=================================\")\n",
    "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))           \n",
    "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
    "\n",
    "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
    "            df_daily_return.columns = ['daily_return']\n",
    "            if df_daily_return['daily_return'].std() !=0:\n",
    "              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
    "                       df_daily_return['daily_return'].std()\n",
    "              print(\"Sharpe: \",sharpe)\n",
    "            print(\"=================================\")\n",
    "            \n",
    "            return self.state, self.reward, self.terminal,{}\n",
    "\n",
    "        else:\n",
    "            #print(\"Model actions: \",actions)\n",
    "            # actions are the portfolio weight\n",
    "            # normalize to sum of 1\n",
    "            #if (np.array(actions) - np.array(actions).min()).sum() != 0:\n",
    "            #  norm_actions = (np.array(actions) - np.array(actions).min()) / (np.array(actions) - np.array(actions).min()).sum()\n",
    "            #else:\n",
    "            #  norm_actions = actions\n",
    "            weights = self.softmax_normalization(actions) \n",
    "            #print(\"Normalized actions: \", weights)\n",
    "            self.actions_memory.append(weights)\n",
    "            last_day_memory = self.data\n",
    "\n",
    "            #load next state\n",
    "            self.day += 1\n",
    "            self.data = self.df.loc[self.day,:]\n",
    "            self.covs = self.data['cov_list'].values[0]\n",
    "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "            self.state = self.state.ravel()\n",
    "            #print(self.state)\n",
    "            # calcualte portfolio return\n",
    "            # individual stocks' return * weight\n",
    "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
    "            # update portfolio value\n",
    "            new_portfolio_value = self.portfolio_value*(1+portfolio_return)\n",
    "            self.portfolio_value = new_portfolio_value\n",
    "\n",
    "            # save into memory\n",
    "            self.portfolio_return_memory.append(portfolio_return)\n",
    "            self.date_memory.append(self.data.date.unique()[0])            \n",
    "            self.asset_memory.append(new_portfolio_value)\n",
    "\n",
    "            # the reward is the new portfolio value or end portfolo value\n",
    "            self.reward = new_portfolio_value \n",
    "            #print(\"Step reward: \", self.reward)\n",
    "            #self.reward = self.reward*self.reward_scaling\n",
    "\n",
    "        return self.state, self.reward, self.terminal, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.asset_memory = [self.initial_amount]\n",
    "        self.day = 0\n",
    "        self.data = self.df.loc[self.day,:]\n",
    "        # load states\n",
    "        self.covs = self.data['cov_list'].values[0]\n",
    "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
    "        self.state = self.state.ravel()\n",
    "        self.portfolio_value = self.initial_amount\n",
    "        #self.cost = 0\n",
    "        #self.trades = 0\n",
    "        self.terminal = False \n",
    "        self.portfolio_return_memory = [0]\n",
    "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
    "        self.date_memory=[self.data.date.unique()[0]] \n",
    "        return self.state\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        return self.state\n",
    "        \n",
    "    def softmax_normalization(self, actions):\n",
    "        numerator = np.exp(actions)\n",
    "        denominator = np.sum(np.exp(actions))\n",
    "        softmax_output = numerator/denominator\n",
    "        return softmax_output\n",
    "\n",
    "    \n",
    "    def save_asset_memory(self):\n",
    "        date_list = self.date_memory\n",
    "        portfolio_return = self.portfolio_return_memory\n",
    "        #print(len(date_list))\n",
    "        #print(len(asset_list))\n",
    "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
    "        return df_account_value\n",
    "\n",
    "    def save_action_memory(self):\n",
    "        # date and close price length must match actions length\n",
    "        date_list = self.date_memory\n",
    "        df_date = pd.DataFrame(date_list)\n",
    "        df_date.columns = ['date']\n",
    "        \n",
    "        action_list = self.actions_memory\n",
    "        df_actions = pd.DataFrame(action_list)\n",
    "        df_actions.columns = self.data.tic.values\n",
    "        df_actions.index = df_date.date\n",
    "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
    "        return df_actions\n",
    "\n",
    "    def _seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def get_sb_env(self):\n",
    "        e = DummyVecEnv([lambda: self])\n",
    "        obs = e.reset()\n",
    "        return e, obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ut1_xe-_BZG4",
    "outputId": "b1052205-928b-41c7-ae1e-eebfc1f48bfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 28, State Space: 28\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "xdqnW3HXBi0j"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"transaction_cost_pct\": 0.001, \n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-QjCNBiUBxcJ",
    "outputId": "01740ff9-843f-475e-b763-497281e9c755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5Mm6IDkFCyN",
    "outputId": "9e028bfe-b949-4098-f027-47beb08ff81c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1008)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e_train_gym.reset().shape\n",
    "e = DummyVecEnv([lambda: e_train_gym])\n",
    "e.reset().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRa5oGsgAWg6"
   },
   "source": [
    "# Train policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "npat6aWYB27h"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3 import A2C, DDPG, PPO, SAC, TD3\n",
    "MODELS = {\"a2c\": A2C, \"ddpg\": DDPG, \"td3\": TD3, \"sac\": SAC, \"ppo\": PPO}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "HWuvYTKbAYLF"
   },
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "class TensorboardCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Custom callback for plotting additional values in tensorboard.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, verbose=0):\n",
    "        super(TensorboardCallback, self).__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        try:\n",
    "            self.logger.record(key=\"train/reward\", value=self.locals[\"rewards\"][0])\n",
    "        except BaseException:\n",
    "            self.logger.record(key=\"train/reward\", value=self.locals[\"reward\"][0])\n",
    "        return True\n",
    "\n",
    "class DRLAgent:\n",
    "    \"\"\"Provides implementations for DRL algorithms\n",
    "    Attributes\n",
    "    ----------\n",
    "        env: gym environment class\n",
    "            user-defined class\n",
    "    Methods\n",
    "    -------\n",
    "        get_model()\n",
    "            setup DRL algorithms\n",
    "        train_model()\n",
    "            train DRL algorithms in a train dataset\n",
    "            and output the trained model\n",
    "        DRL_prediction()\n",
    "            make a prediction in a test dataset and get results\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "\n",
    "    def get_model(\n",
    "        self,\n",
    "        model_name,\n",
    "        policy=\"MlpPolicy\",\n",
    "        policy_kwargs=None,\n",
    "        model_kwargs=None,\n",
    "        verbose=1,\n",
    "        seed=None,\n",
    "        tensorboard_log=None,\n",
    "    ):\n",
    "        if model_name not in MODELS:\n",
    "            raise NotImplementedError(\"NotImplementedError\")\n",
    "\n",
    "        if model_kwargs is None:\n",
    "            model_kwargs = MODEL_KWARGS[model_name]\n",
    "\n",
    "        if \"action_noise\" in model_kwargs:\n",
    "            n_actions = self.env.action_space.shape[-1]\n",
    "            model_kwargs[\"action_noise\"] = NOISE[model_kwargs[\"action_noise\"]](\n",
    "                mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions)\n",
    "            )\n",
    "        print(model_kwargs)\n",
    "        model = MODELS[model_name](\n",
    "            policy=policy,\n",
    "            env=self.env,\n",
    "            tensorboard_log=tensorboard_log,\n",
    "            verbose=verbose,\n",
    "            policy_kwargs=policy_kwargs,\n",
    "            seed=seed,\n",
    "            **model_kwargs,\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    def train_model(self, model, tb_log_name, total_timesteps=5000):\n",
    "        model = model.learn(\n",
    "            total_timesteps=total_timesteps,\n",
    "            tb_log_name=tb_log_name,\n",
    "            callback=TensorboardCallback(),\n",
    "        )\n",
    "        return model\n",
    "\n",
    "    @staticmethod\n",
    "    def DRL_prediction(model, environment):\n",
    "        test_env, test_obs = environment.get_sb_env()\n",
    "        \"\"\"make a prediction\"\"\"\n",
    "        account_memory = []\n",
    "        actions_memory = []\n",
    "        test_env.reset()\n",
    "        for i in range(len(environment.df.index.unique())):\n",
    "            action, _states = model.predict(test_obs)\n",
    "            # account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "            # actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "            test_obs, rewards, dones, info = test_env.step(action)\n",
    "            if i == (len(environment.df.index.unique()) - 2):\n",
    "                account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "                actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "            if dones[0]:\n",
    "                print(\"hit end!\")\n",
    "                break\n",
    "        return account_memory[0], actions_memory[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUPDfLyJBec2",
    "outputId": "d0107120-68d2-4e37-9770-a2b9f3274aae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0002}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "\n",
    "A2C_PARAMS = {\"n_steps\": 5, \"ent_coef\": 0.005, \"learning_rate\": 0.0002}\n",
    "model_a2c = agent.get_model(model_name=\"a2c\",model_kwargs = A2C_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60MG20gSBoD8",
    "outputId": "ad0d769d-59d2-4249-f255-afab21697eb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 343       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | 1.85e+08  |\n",
      "|    reward             | 1507138.5 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 2.38e+13  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| time/                 |           |\n",
      "|    fps                | 345       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -39.6     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0002    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | 2.15e+08  |\n",
      "|    reward             | 1864927.0 |\n",
      "|    std                | 0.995     |\n",
      "|    value_loss         | 3.66e+13  |\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                                tb_log_name='a2c',\n",
    "                                total_timesteps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CsQ56TdEXdA"
   },
   "source": [
    "# Trading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "vXTMBpjdDEl2"
   },
   "outputs": [],
   "source": [
    "trade = data_split(df,'2020-07-01', '2021-10-31')\n",
    "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DpoXVisAEqNo",
    "outputId": "99227114-7340-4603-d40d-53e108112285"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9436, 19)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l0GvBftBcx3o",
    "outputId": "c60bbfd7-5fdd-4082-f9c8-dc4f27de401d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1429449.5448283376\n",
      "Sharpe:  2.001964404510939\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "df_daily_return, df_actions = DRLAgent.DRL_prediction(model=trained_a2c,\n",
    "                        environment = e_trade_gym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "r5MS3QxQiCjP",
    "outputId": "1dc8161b-bf13-4fbd-b1f7-c038b4de3314"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>0.004743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-06</td>\n",
       "      <td>0.015841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>-0.010441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-08</td>\n",
       "      <td>0.005679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  daily_return\n",
       "0  2020-07-01      0.000000\n",
       "1  2020-07-02      0.004743\n",
       "2  2020-07-06      0.015841\n",
       "3  2020-07-07     -0.010441\n",
       "4  2020-07-08      0.005679"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "MFuofZZXjPLy",
    "outputId": "3b12adb4-7817-41ee-ac42-1485067de972"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AMGN</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BA</th>\n",
       "      <th>CAT</th>\n",
       "      <th>CRM</th>\n",
       "      <th>CSCO</th>\n",
       "      <th>CVX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>GS</th>\n",
       "      <th>...</th>\n",
       "      <th>MMM</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBA</th>\n",
       "      <th>WMT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-02</th>\n",
       "      <td>0.061647</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.045620</td>\n",
       "      <td>0.039061</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031382</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.061647</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.040835</td>\n",
       "      <td>0.061647</td>\n",
       "      <td>0.061647</td>\n",
       "      <td>0.061647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-06</th>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.047250</td>\n",
       "      <td>0.063149</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.063149</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.063149</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.046266</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.054575</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.063149</td>\n",
       "      <td>0.035446</td>\n",
       "      <td>0.023231</td>\n",
       "      <td>0.044574</td>\n",
       "      <td>0.063149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-07</th>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.047579</td>\n",
       "      <td>0.070950</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.035642</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.044541</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>0.070950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-08</th>\n",
       "      <td>0.072268</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.044178</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.057015</td>\n",
       "      <td>0.072268</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026682</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.026586</td>\n",
       "      <td>0.049381</td>\n",
       "      <td>0.027809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL      AMGN       AXP        BA       CAT       CRM  \\\n",
       "date                                                                     \n",
       "2020-07-01  0.035714  0.035714  0.035714  0.035714  0.035714  0.035714   \n",
       "2020-07-02  0.061647  0.022679  0.022679  0.045620  0.039061  0.022679   \n",
       "2020-07-06  0.023231  0.047250  0.063149  0.023231  0.063149  0.023231   \n",
       "2020-07-07  0.026101  0.026101  0.026101  0.026101  0.026101  0.047579   \n",
       "2020-07-08  0.072268  0.026586  0.026586  0.026586  0.044178  0.026586   \n",
       "\n",
       "                CSCO       CVX       DIS        GS  ...       MMM       MRK  \\\n",
       "date                                                ...                       \n",
       "2020-07-01  0.035714  0.035714  0.035714  0.035714  ...  0.035714  0.035714   \n",
       "2020-07-02  0.022679  0.022679  0.022679  0.022679  ...  0.031382  0.031354   \n",
       "2020-07-06  0.063149  0.023231  0.046266  0.023231  ...  0.023231  0.023231   \n",
       "2020-07-07  0.070950  0.026101  0.026101  0.026101  ...  0.026101  0.026101   \n",
       "2020-07-08  0.057015  0.072268  0.026586  0.026586  ...  0.026682  0.026586   \n",
       "\n",
       "                MSFT       NKE        PG       TRV       UNH        VZ  \\\n",
       "date                                                                     \n",
       "2020-07-01  0.035714  0.035714  0.035714  0.035714  0.035714  0.035714   \n",
       "2020-07-02  0.022679  0.061647  0.022679  0.022679  0.040835  0.061647   \n",
       "2020-07-06  0.054575  0.023231  0.023231  0.063149  0.035446  0.023231   \n",
       "2020-07-07  0.026101  0.035642  0.026101  0.044541  0.026101  0.026101   \n",
       "2020-07-08  0.026586  0.026586  0.026586  0.026586  0.026586  0.026586   \n",
       "\n",
       "                 WBA       WMT  \n",
       "date                            \n",
       "2020-07-01  0.035714  0.035714  \n",
       "2020-07-02  0.061647  0.061647  \n",
       "2020-07-06  0.044574  0.063149  \n",
       "2020-07-07  0.027152  0.070950  \n",
       "2020-07-08  0.049381  0.027809  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jihGclF-k1OO",
    "outputId": "8c0f51a9-98b2-4cf3-b581-a1259cfad649"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyfolio\n",
      "  Downloading pyfolio-0.9.2.tar.gz (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 2.4 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pyfolio) (7.18.1)\n",
      "Requirement already satisfied: matplotlib>=1.4.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pyfolio) (3.2.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pyfolio) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.18.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pyfolio) (1.2.4)\n",
      "Requirement already satisfied: pytz>=2014.10 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pyfolio) (2021.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pyfolio) (1.6.2)\n",
      "Requirement already satisfied: scikit-learn>=0.16.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pyfolio) (0.24.1)\n",
      "Collecting seaborn>=0.7.1\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "\u001b[K     |████████████████████████████████| 292 kB 5.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting empyrical>=0.5.0\n",
      "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 2.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas-datareader>=0.2\n",
      "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
      "\u001b[K     |████████████████████████████████| 109 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pygments in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio) (2.7.1)\n",
      "Requirement already satisfied: appnope in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio) (0.1.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio) (5.0.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio) (4.8.0)\n",
      "Requirement already satisfied: backcall in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio) (52.0.0.post20210125)\n",
      "Requirement already satisfied: decorator in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.10 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from ipython>=3.2.3->pyfolio) (3.0.8)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from jedi>=0.10->ipython>=3.2.3->pyfolio) (0.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=1.4.0->pyfolio) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=1.4.0->pyfolio) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=1.4.0->pyfolio) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from matplotlib>=1.4.0->pyfolio) (1.3.1)\n",
      "Requirement already satisfied: six in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=1.4.0->pyfolio) (1.15.0)\n",
      "Requirement already satisfied: lxml in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (4.6.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.27.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio) (0.2.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (1.26.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2021.10.8)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from scikit-learn>=0.16.1->pyfolio) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from scikit-learn>=0.16.1->pyfolio) (2.1.0)\n",
      "Requirement already satisfied: ipython-genutils in /Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages (from traitlets>=4.2->ipython>=3.2.3->pyfolio) (0.2.0)\n",
      "Building wheels for collected packages: pyfolio, empyrical\n",
      "  Building wheel for pyfolio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfolio: filename=pyfolio-0.9.2-py3-none-any.whl size=88667 sha256=9fb37206dfbcee51820ebd5e148ff75fbcc7e04f291582c13f1769ddd5afb71e\n",
      "  Stored in directory: /Users/liupeng/Library/Caches/pip/wheels/e4/96/9b/0dfff5453e702fd780a099b7c850521099c5ec0dfafae189f9\n",
      "  Building wheel for empyrical (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39764 sha256=2cd2cb0f57408b84924d39e61e74dc6ede81810fe3813e0d7fca290296feae9e\n",
      "  Stored in directory: /Users/liupeng/Library/Caches/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
      "Successfully built pyfolio empyrical\n",
      "Installing collected packages: pandas-datareader, seaborn, empyrical, pyfolio\n",
      "Successfully installed empyrical-0.5.5 pandas-datareader-0.10.0 pyfolio-0.9.2 seaborn-0.11.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyfolio\n",
    "\n",
    "def convert_daily_return_to_pyfolio_ts(df):\n",
    "    strategy_ret = df.copy()\n",
    "    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])\n",
    "    strategy_ret.set_index(\"date\", drop=False, inplace=True)\n",
    "    strategy_ret.index = strategy_ret.index.tz_localize(\"UTC\")\n",
    "    del strategy_ret[\"date\"]\n",
    "    ts = pd.Series(strategy_ret[\"daily_return\"].values, index=strategy_ret.index)\n",
    "    return ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lSSwTT4omQPF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liupeng/opt/anaconda3/envs/py37/lib/python3.7/site-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  'Module \"zipline.assets\" not found; mutltipliers will not be applied' +\n"
     ]
    }
   ],
   "source": [
    "from pyfolio import timeseries\n",
    "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return)\n",
    "perf_func = timeseries.perf_stats \n",
    "perf_stats_all = perf_func( returns=DRL_strat, \n",
    "                              factor_returns=DRL_strat, \n",
    "                                positions=None, transactions=None, turnover_denom=\"AGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcV0nxoomlkx",
    "outputId": "bdb05924-f64f-4de1-d532-47f0926e98f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============DRL Strategy Stats===========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Annual return          0.306265\n",
       "Cumulative returns     0.429450\n",
       "Annual volatility      0.138280\n",
       "Sharpe ratio           2.001964\n",
       "Calmar ratio           3.795849\n",
       "Stability              0.909727\n",
       "Max drawdown          -0.080684\n",
       "Omega ratio            1.395166\n",
       "Sortino ratio          3.100965\n",
       "Skew                   0.097503\n",
       "Kurtosis               2.456289\n",
       "Tail ratio             1.151844\n",
       "Daily value at risk   -0.016323\n",
       "Alpha                  0.000000\n",
       "Beta                   1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"==============DRL Strategy Stats===========\")\n",
    "perf_stats_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMmDEwW1X5XP"
   },
   "source": [
    "# DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "z7hdowlRxKgn"
   },
   "outputs": [],
   "source": [
    "import warnings ; warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import threading\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from itertools import cycle, count\n",
    "from textwrap import wrap\n",
    "\n",
    "# import pybullet_envs\n",
    "import matplotlib\n",
    "import subprocess\n",
    "import os.path\n",
    "import tempfile\n",
    "import random\n",
    "# import base64pybullet_envs\n",
    "import pprint\n",
    "import glob\n",
    "import time      \n",
    "import json\n",
    "import sys\n",
    "import gym\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from gym import wrappers\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from subprocess import check_output\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "LEAVE_PRINT_EVERY_N_SECS = 300\n",
    "ERASE_LINE = '\\x1b[2K'\n",
    "EPS = 1e-6\n",
    "BEEP = lambda: os.system(\"printf '\\a'\")\n",
    "RESULTS_DIR = os.path.join('..', 'results')\n",
    "SEEDS = [12, 34, 56]#, 78, 90, 100, 120, 150, 180, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "3-xpHEZXX7ln"
   },
   "outputs": [],
   "source": [
    "class FCQV(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 output_dim, \n",
    "                 hidden_dims=(32,32), \n",
    "                 activation_fc=F.relu):\n",
    "        super(FCQV, self).__init__()\n",
    "        self.activation_fc = activation_fc\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            in_dim = hidden_dims[i]\n",
    "            if i == 0: \n",
    "                in_dim += output_dim\n",
    "            hidden_layer = nn.Linear(in_dim, hidden_dims[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], 1)\n",
    "\n",
    "        device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda:0\"\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "    \n",
    "    def _format(self, state, action):\n",
    "        x, u = state, action\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, \n",
    "                             device=self.device, \n",
    "                             dtype=torch.float32)\n",
    "            x = x.unsqueeze(0)\n",
    "        if not isinstance(u, torch.Tensor):\n",
    "            u = torch.tensor(u, \n",
    "                             device=self.device, \n",
    "                             dtype=torch.float32)\n",
    "            u = u.unsqueeze(0)\n",
    "        return x, u\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x, u = self._format(state, action)\n",
    "        # print(x.shape)\n",
    "        x = self.activation_fc(self.input_layer(x))\n",
    "        for i, hidden_layer in enumerate(self.hidden_layers):\n",
    "            if i == 0:\n",
    "                x = torch.cat((x, u), dim=1)\n",
    "            x = self.activation_fc(hidden_layer(x))\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "    def load(self, experiences):\n",
    "        states, actions, new_states, rewards, is_terminals = experiences\n",
    "        states = torch.from_numpy(states).float().to(self.device)\n",
    "        actions = torch.from_numpy(actions).float().to(self.device)\n",
    "        new_states = torch.from_numpy(new_states).float().to(self.device)\n",
    "        rewards = torch.from_numpy(rewards).float().to(self.device)\n",
    "        is_terminals = torch.from_numpy(is_terminals).float().to(self.device)\n",
    "        return states, actions, new_states, rewards, is_terminals\n",
    "\n",
    "\n",
    "class FCDP(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim,\n",
    "                 action_bounds,\n",
    "                 hidden_dims=(32,32), \n",
    "                 activation_fc=F.relu,\n",
    "                 out_activation_fc=F.tanh):\n",
    "        super(FCDP, self).__init__()\n",
    "        self.activation_fc = activation_fc\n",
    "        self.out_activation_fc = out_activation_fc\n",
    "        self.env_min, self.env_max = action_bounds\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            hidden_layer = nn.Linear(hidden_dims[i], hidden_dims[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], len(self.env_max))\n",
    "\n",
    "        device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda:0\"\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "        \n",
    "        self.env_min = torch.tensor(self.env_min,\n",
    "                                    device=self.device, \n",
    "                                    dtype=torch.float32)\n",
    "\n",
    "        self.env_max = torch.tensor(self.env_max,\n",
    "                                    device=self.device, \n",
    "                                    dtype=torch.float32)\n",
    "        \n",
    "        self.nn_min = self.out_activation_fc(\n",
    "            torch.Tensor([float('-inf')])).to(self.device)\n",
    "        self.nn_max = self.out_activation_fc(\n",
    "            torch.Tensor([float('inf')])).to(self.device)\n",
    "        self.rescale_fn = lambda x: (x - self.nn_min) * (self.env_max - self.env_min) / \\\n",
    "                                    (self.nn_max - self.nn_min) + self.env_min\n",
    "\n",
    "    def _format(self, state):\n",
    "        x = state\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, \n",
    "                             device=self.device, \n",
    "                             dtype=torch.float32)\n",
    "            x = x.unsqueeze(0)\n",
    "        return x\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self._format(state)\n",
    "        # print(1)\n",
    "        # print(x.shape)\n",
    "        x = self.activation_fc(self.input_layer(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation_fc(hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        x = self.out_activation_fc(x)\n",
    "        return self.rescale_fn(x)\n",
    "\n",
    "\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self, \n",
    "                 max_size=10000, \n",
    "                 batch_size=64):\n",
    "        self.ss_mem = np.empty(shape=(max_size), dtype=np.ndarray)\n",
    "        self.as_mem = np.empty(shape=(max_size), dtype=np.ndarray)\n",
    "        self.rs_mem = np.empty(shape=(max_size), dtype=np.ndarray)\n",
    "        self.ps_mem = np.empty(shape=(max_size), dtype=np.ndarray)\n",
    "        self.ds_mem = np.empty(shape=(max_size), dtype=np.ndarray)\n",
    "\n",
    "        self.max_size = max_size\n",
    "        self.batch_size = batch_size\n",
    "        self._idx = 0\n",
    "        self.size = 0\n",
    "    \n",
    "    def store(self, sample):\n",
    "        s, a, r, p, d = sample\n",
    "        self.ss_mem[self._idx] = s\n",
    "        self.as_mem[self._idx] = a\n",
    "        self.rs_mem[self._idx] = r\n",
    "        self.ps_mem[self._idx] = p\n",
    "        self.ds_mem[self._idx] = d\n",
    "        \n",
    "        self._idx += 1\n",
    "        self._idx = self._idx % self.max_size\n",
    "\n",
    "        self.size += 1\n",
    "        self.size = min(self.size, self.max_size)\n",
    "\n",
    "    def sample(self, batch_size=None):\n",
    "        if batch_size == None:\n",
    "            batch_size = self.batch_size\n",
    "\n",
    "        idxs = np.random.choice(\n",
    "            self.size, batch_size, replace=False)\n",
    "        experiences = np.vstack(self.ss_mem[idxs]), \\\n",
    "                      np.vstack(self.as_mem[idxs]), \\\n",
    "                      np.vstack(self.rs_mem[idxs]), \\\n",
    "                      np.vstack(self.ps_mem[idxs]), \\\n",
    "                      np.vstack(self.ds_mem[idxs])\n",
    "        return experiences\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "\n",
    "class GreedyStrategy():\n",
    "    def __init__(self, bounds):\n",
    "        self.low, self.high = bounds\n",
    "        self.ratio_noise_injected = 0\n",
    "\n",
    "    def select_action(self, model, state):\n",
    "        with torch.no_grad():\n",
    "            greedy_action = model(state).cpu().detach().data.numpy().squeeze()\n",
    "\n",
    "        action = np.clip(greedy_action, self.low, self.high)\n",
    "        return np.reshape(action, self.high.shape)\n",
    "\n",
    "\n",
    "\n",
    "class NormalNoiseStrategy():\n",
    "    def __init__(self, bounds, exploration_noise_ratio=0.1):\n",
    "        self.low, self.high = bounds\n",
    "        self.exploration_noise_ratio = exploration_noise_ratio\n",
    "        self.ratio_noise_injected = 0\n",
    "\n",
    "    def select_action(self, model, state, max_exploration=False):\n",
    "        if max_exploration:\n",
    "            noise_scale = self.high\n",
    "        else:\n",
    "            noise_scale = self.exploration_noise_ratio * self.high\n",
    "\n",
    "        with torch.no_grad():\n",
    "            greedy_action = model(state).cpu().detach().data.numpy().squeeze()\n",
    "\n",
    "        noise = np.random.normal(loc=0, scale=noise_scale, size=len(self.high))\n",
    "        noisy_action = greedy_action + noise\n",
    "        action = np.clip(noisy_action, self.low, self.high)\n",
    "        \n",
    "        self.ratio_noise_injected = np.mean(abs((greedy_action - action)/(self.high - self.low)))\n",
    "        return action\n",
    "\n",
    "\n",
    "class DDPG():\n",
    "    def __init__(self, \n",
    "                 replay_buffer_fn,\n",
    "                 policy_model_fn, \n",
    "                 policy_max_grad_norm, \n",
    "                 policy_optimizer_fn, \n",
    "                 policy_optimizer_lr,\n",
    "                 value_model_fn, \n",
    "                 value_max_grad_norm, \n",
    "                 value_optimizer_fn, \n",
    "                 value_optimizer_lr, \n",
    "                 training_strategy_fn,\n",
    "                 evaluation_strategy_fn,\n",
    "                 n_warmup_batches,\n",
    "                 update_target_every_steps,\n",
    "                 tau):\n",
    "        self.replay_buffer_fn = replay_buffer_fn\n",
    "\n",
    "        self.policy_model_fn = policy_model_fn\n",
    "        self.policy_max_grad_norm = policy_max_grad_norm\n",
    "        self.policy_optimizer_fn = policy_optimizer_fn\n",
    "        self.policy_optimizer_lr = policy_optimizer_lr\n",
    "        \n",
    "        self.value_model_fn = value_model_fn\n",
    "        self.value_max_grad_norm = value_max_grad_norm\n",
    "        self.value_optimizer_fn = value_optimizer_fn\n",
    "        self.value_optimizer_lr = value_optimizer_lr\n",
    "\n",
    "        self.training_strategy_fn = training_strategy_fn\n",
    "        self.evaluation_strategy_fn = evaluation_strategy_fn\n",
    "\n",
    "        self.n_warmup_batches = n_warmup_batches\n",
    "        self.update_target_every_steps = update_target_every_steps\n",
    "        self.tau = tau\n",
    "\n",
    "    def optimize_model(self, experiences):\n",
    "        states, actions, rewards, next_states, is_terminals = experiences\n",
    "        batch_size = len(is_terminals)\n",
    "\n",
    "        argmax_a_q_sp = self.target_policy_model(next_states)\n",
    "        max_a_q_sp = self.target_value_model(next_states, argmax_a_q_sp)\n",
    "        target_q_sa = rewards + self.gamma * max_a_q_sp * (1 - is_terminals)\n",
    "        q_sa = self.online_value_model(states, actions)\n",
    "        td_error = q_sa - target_q_sa.detach()\n",
    "        value_loss = td_error.pow(2).mul(0.5).mean()\n",
    "        self.value_optimizer.zero_grad()\n",
    "        value_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.online_value_model.parameters(), \n",
    "                                       self.value_max_grad_norm)\n",
    "        self.value_optimizer.step()\n",
    "\n",
    "        argmax_a_q_s = self.online_policy_model(states)\n",
    "        max_a_q_s = self.online_value_model(states, argmax_a_q_s)\n",
    "        policy_loss = -max_a_q_s.mean()\n",
    "        self.policy_optimizer.zero_grad()\n",
    "        policy_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(self.online_policy_model.parameters(), \n",
    "                                       self.policy_max_grad_norm)        \n",
    "        self.policy_optimizer.step()\n",
    "\n",
    "    def interaction_step(self, state, env):\n",
    "        min_samples = self.replay_buffer.batch_size * self.n_warmup_batches\n",
    "        action = self.training_strategy.select_action(self.online_policy_model, \n",
    "                                                      state, \n",
    "                                                      len(self.replay_buffer) < min_samples)\n",
    "        new_state, reward, is_terminal, info = env.step(action)\n",
    "        is_truncated = 'TimeLimit.truncated' in info and info['TimeLimit.truncated']\n",
    "        is_failure = is_terminal and not is_truncated\n",
    "        experience = (state, action, reward, new_state, float(is_failure))\n",
    "        self.replay_buffer.store(experience)\n",
    "        self.episode_reward[-1] += reward\n",
    "        self.episode_timestep[-1] += 1\n",
    "        self.episode_exploration[-1] += self.training_strategy.ratio_noise_injected\n",
    "        return new_state, is_terminal\n",
    "    \n",
    "    def update_networks(self, tau=None):\n",
    "        tau = self.tau if tau is None else tau\n",
    "        for target, online in zip(self.target_value_model.parameters(), \n",
    "                                  self.online_value_model.parameters()):\n",
    "            target_ratio = (1.0 - self.tau) * target.data\n",
    "            online_ratio = self.tau * online.data\n",
    "            mixed_weights = target_ratio + online_ratio\n",
    "            target.data.copy_(mixed_weights)\n",
    "\n",
    "        for target, online in zip(self.target_policy_model.parameters(), \n",
    "                                  self.online_policy_model.parameters()):\n",
    "            target_ratio = (1.0 - self.tau) * target.data\n",
    "            online_ratio = self.tau * online.data\n",
    "            mixed_weights = target_ratio + online_ratio\n",
    "            target.data.copy_(mixed_weights)\n",
    "\n",
    "    def train(self, make_env_fn, make_env_kargs, seed, gamma, \n",
    "              max_minutes, max_episodes, goal_mean_100_reward):\n",
    "        training_start, last_debug_time = time.time(), float('-inf')\n",
    "\n",
    "        self.checkpoint_dir = tempfile.mkdtemp()\n",
    "        self.make_env_fn = make_env_fn\n",
    "        self.make_env_kargs = make_env_kargs\n",
    "        self.seed = seed\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        env = self.make_env_fn(**self.make_env_kargs, seed=self.seed)\n",
    "        torch.manual_seed(self.seed) ; np.random.seed(self.seed) ; random.seed(self.seed)\n",
    "    \n",
    "        nS, nA = env.observation_space.shape[0], env.action_space.shape[0]\n",
    "        action_bounds = env.action_space.low, env.action_space.high\n",
    "        self.episode_timestep = []\n",
    "        self.episode_reward = []\n",
    "        self.episode_seconds = []\n",
    "        self.evaluation_scores = []        \n",
    "        self.episode_exploration = []\n",
    "        \n",
    "        self.target_value_model = self.value_model_fn(nS, nA)\n",
    "        self.online_value_model = self.value_model_fn(nS, nA)\n",
    "        self.target_policy_model = self.policy_model_fn(nS, action_bounds)\n",
    "        self.online_policy_model = self.policy_model_fn(nS, action_bounds)\n",
    "        self.update_networks(tau=1.0)\n",
    "        self.value_optimizer = self.value_optimizer_fn(self.online_value_model, \n",
    "                                                       self.value_optimizer_lr)        \n",
    "        self.policy_optimizer = self.policy_optimizer_fn(self.online_policy_model, \n",
    "                                                         self.policy_optimizer_lr)\n",
    "\n",
    "        self.replay_buffer = self.replay_buffer_fn()\n",
    "        self.training_strategy = training_strategy_fn(action_bounds)\n",
    "        self.evaluation_strategy = evaluation_strategy_fn(action_bounds)\n",
    "                    \n",
    "        result = np.empty((max_episodes, 5))\n",
    "        result[:] = np.nan\n",
    "        training_time = 0\n",
    "        for episode in range(1, max_episodes + 1):\n",
    "            episode_start = time.time()\n",
    "            \n",
    "            state, is_terminal = env.reset(), False\n",
    "            self.episode_reward.append(0.0)\n",
    "            self.episode_timestep.append(0.0)\n",
    "            self.episode_exploration.append(0.0)\n",
    "\n",
    "            for step in count():\n",
    "                # print(state.shape)\n",
    "                # print(state)\n",
    "                state, is_terminal = self.interaction_step(state, env)\n",
    "\n",
    "                min_samples = self.replay_buffer.batch_size * self.n_warmup_batches\n",
    "                if len(self.replay_buffer) > min_samples:\n",
    "                    experiences = self.replay_buffer.sample()\n",
    "                    experiences = self.online_value_model.load(experiences)\n",
    "                    self.optimize_model(experiences)\n",
    "\n",
    "                if np.sum(self.episode_timestep) % self.update_target_every_steps == 0:\n",
    "                    self.update_networks()\n",
    "\n",
    "                if is_terminal:\n",
    "                    gc.collect()\n",
    "                    break\n",
    "            \n",
    "            # stats\n",
    "            episode_elapsed = time.time() - episode_start\n",
    "            self.episode_seconds.append(episode_elapsed)\n",
    "            training_time += episode_elapsed\n",
    "            evaluation_score, _ = self.evaluate(self.online_policy_model, env)\n",
    "            self.save_checkpoint(episode-1, self.online_policy_model)\n",
    "\n",
    "            total_step = int(np.sum(self.episode_timestep))\n",
    "            self.evaluation_scores.append(evaluation_score)\n",
    "            \n",
    "            mean_10_reward = np.mean(self.episode_reward[-10:])\n",
    "            std_10_reward = np.std(self.episode_reward[-10:])\n",
    "            mean_100_reward = np.mean(self.episode_reward[-100:])\n",
    "            std_100_reward = np.std(self.episode_reward[-100:])\n",
    "            mean_100_eval_score = np.mean(self.evaluation_scores[-100:])\n",
    "            std_100_eval_score = np.std(self.evaluation_scores[-100:])\n",
    "            lst_100_exp_rat = np.array(\n",
    "                self.episode_exploration[-100:])/np.array(self.episode_timestep[-100:])\n",
    "            mean_100_exp_rat = np.mean(lst_100_exp_rat)\n",
    "            std_100_exp_rat = np.std(lst_100_exp_rat)\n",
    "            \n",
    "            wallclock_elapsed = time.time() - training_start\n",
    "            result[episode-1] = total_step, mean_100_reward, \\\n",
    "                mean_100_eval_score, training_time, wallclock_elapsed\n",
    "            \n",
    "            reached_debug_time = time.time() - last_debug_time >= LEAVE_PRINT_EVERY_N_SECS\n",
    "            reached_max_minutes = wallclock_elapsed >= max_minutes * 60\n",
    "            reached_max_episodes = episode >= max_episodes\n",
    "            reached_goal_mean_reward = mean_100_eval_score >= goal_mean_100_reward\n",
    "            training_is_over = reached_max_minutes or \\\n",
    "                               reached_max_episodes or \\\n",
    "                               reached_goal_mean_reward\n",
    "            elapsed_str = time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - training_start))\n",
    "            debug_message = 'el {}, ep {:04}, ts {:07}, '\n",
    "            debug_message += 'ar 10 {:05.1f}\\u00B1{:05.1f}, '\n",
    "            debug_message += '100 {:05.1f}\\u00B1{:05.1f}, '\n",
    "            debug_message += 'ex 100 {:02.1f}\\u00B1{:02.1f}, '\n",
    "            debug_message += 'ev {:05.1f}\\u00B1{:05.1f}'\n",
    "            debug_message = debug_message.format(\n",
    "                elapsed_str, episode-1, total_step, mean_10_reward, std_10_reward, \n",
    "                mean_100_reward, std_100_reward, mean_100_exp_rat, std_100_exp_rat,\n",
    "                mean_100_eval_score, std_100_eval_score)\n",
    "            print(debug_message, end='\\r', flush=True)\n",
    "            if reached_debug_time or training_is_over:\n",
    "                print(ERASE_LINE + debug_message, flush=True)\n",
    "                last_debug_time = time.time()\n",
    "            if training_is_over:\n",
    "                if reached_max_minutes: print(u'--> reached_max_minutes \\u2715')\n",
    "                if reached_max_episodes: print(u'--> reached_max_episodes \\u2715')\n",
    "                if reached_goal_mean_reward: print(u'--> reached_goal_mean_reward \\u2713')\n",
    "                break\n",
    "                \n",
    "        final_eval_score, score_std = self.evaluate(self.online_policy_model, env, n_episodes=100)\n",
    "        wallclock_time = time.time() - training_start\n",
    "        print('Training complete.')\n",
    "        print('Final evaluation score {:.2f}\\u00B1{:.2f} in {:.2f}s training time,'\n",
    "              ' {:.2f}s wall-clock time.\\n'.format(\n",
    "                  final_eval_score, score_std, training_time, wallclock_time))\n",
    "        env.close() ; del env\n",
    "        self.get_cleaned_checkpoints()\n",
    "        return result, final_eval_score, training_time, wallclock_time\n",
    "    \n",
    "    def evaluate(self, eval_policy_model, eval_env, n_episodes=1):\n",
    "        rs = []\n",
    "        for _ in range(n_episodes):\n",
    "            s, d = eval_env.reset(), False\n",
    "            rs.append(0)\n",
    "            for _ in count():\n",
    "                a = self.evaluation_strategy.select_action(eval_policy_model, s)\n",
    "                s, r, d, _ = eval_env.step(a)\n",
    "                rs[-1] += r\n",
    "                if d: break\n",
    "        return np.mean(rs), np.std(rs)\n",
    "\n",
    "    def get_cleaned_checkpoints(self, n_checkpoints=4):\n",
    "        try: \n",
    "            return self.checkpoint_paths\n",
    "        except AttributeError:\n",
    "            self.checkpoint_paths = {}\n",
    "\n",
    "        paths = glob.glob(os.path.join(self.checkpoint_dir, '*.tar'))\n",
    "        paths_dic = {int(path.split('.')[-2]):path for path in paths}\n",
    "        last_ep = max(paths_dic.keys())\n",
    "        # checkpoint_idxs = np.geomspace(1, last_ep+1, n_checkpoints, endpoint=True, dtype=np.int)-1\n",
    "        checkpoint_idxs = np.linspace(1, last_ep+1, n_checkpoints, endpoint=True, dtype=np.int)-1\n",
    "\n",
    "        for idx, path in paths_dic.items():\n",
    "            if idx in checkpoint_idxs:\n",
    "                self.checkpoint_paths[idx] = path\n",
    "            else:\n",
    "                os.unlink(path)\n",
    "\n",
    "        return self.checkpoint_paths\n",
    "\n",
    "    def save_checkpoint(self, episode_idx, model):\n",
    "        torch.save(model.state_dict(), \n",
    "                   os.path.join(self.checkpoint_dir, 'model.{}.tar'.format(episode_idx)))\n",
    "        \n",
    "def get_make_env_fn(**kargs):\n",
    "    def make_env_fn(env_name, seed=None, render=None, record=False,\n",
    "                    unwrapped=False, monitor_mode=None, \n",
    "                    inner_wrappers=None, outer_wrappers=None):\n",
    "        mdir = tempfile.mkdtemp()\n",
    "        # env = None\n",
    "        # if render:\n",
    "        #     try:\n",
    "        #         env = gym.make(env_name, render=render)\n",
    "        #     except:\n",
    "        #         pass\n",
    "        # if env is None:\n",
    "        #     env = gym.make(env_name)\n",
    "        if seed is not None: \n",
    "            random.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            # tf.random.set_random_seed(seed)\n",
    "            torch.manual_seed(seed)\n",
    "        # env = env.unwrapped if unwrapped else env\n",
    "        # if inner_wrappers:\n",
    "        #     for wrapper in inner_wrappers:\n",
    "        #         env = wrapper(env)\n",
    "        # env = wrappers.Monitor(\n",
    "        #     env, mdir, force=True, \n",
    "        #     mode=monitor_mode, \n",
    "        #     video_callable=lambda e_idx: record) if monitor_mode else env\n",
    "        # if outer_wrappers:\n",
    "        #     for wrapper in outer_wrappers:\n",
    "        #         env = wrapper(env)\n",
    "        env = StockPortfolioEnv(df = train, **env_kwargs)\n",
    "        return env\n",
    "    return make_env_fn, kargs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yUBJE2S-YB_O",
    "outputId": "61b90311-dc6c-409e-f8ef-9d8d8e8ec45e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4664860.553993328\n",
      "Sharpe:  0.827949210521489\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4743500.768258629\n",
      "Sharpe:  0.8407885291965188\n",
      "=================================\n",
      "\u001b[2Kel 00:01:11, ep 0000, ts 0002893, ar 10 7807253184.9±000.0, 100 7807253184.9±000.0, ex 100 0.1±0.0, ev 7937400152.4±000.0\n",
      "--> reached_goal_mean_reward ✓\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-cef64fd13431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     result, final_eval_score, training_time, wallclock_time = agent.train(\n\u001b[1;32m     50\u001b[0m         \u001b[0mmake_env_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_env_kargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_minutes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         goal_mean_100_reward)\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mddpg_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_eval_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_eval_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-b348f832e7a3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, make_env_fn, make_env_kargs, seed, gamma, max_minutes, max_episodes, goal_mean_100_reward)\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mfinal_eval_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monline_policy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0mwallclock_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtraining_start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training complete.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-b348f832e7a3>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_policy_model, eval_env, n_episodes)\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_policy_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m                 \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m                 \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-9182d5d56f54>\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'daily_return'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdaily_return\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cumulative_reward.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m     \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2124\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2125\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2126\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2127\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m         }\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpil_kwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    391\u001b[0m              (self.toolbar._wait_cursor_for_draw_cm() if self.toolbar\n\u001b[1;32m    392\u001b[0m               else nullcontext()):\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1225\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_gid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1229\u001b[0m                                                                 renderer)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \"\"\"\n\u001b[1;32m   1103\u001b[0m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mformat_ticks\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;34m\"\"\"Return the tick labels for all the ticks at once.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;34m\"\"\"Return the tick labels for all the ticks at once.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, pos)\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfix_minus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_scientific\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mfix_minus\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mReplace\u001b[0m \u001b[0mhyphens\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0municode\u001b[0m \u001b[0mminus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \"\"\"\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text.usetex'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'axes.unicode_minus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcsetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_backend_sentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ddpg_results = []\n",
    "best_agent, best_eval_score = None, float('-inf')\n",
    "for seed in SEEDS:\n",
    "    environment_settings = {\n",
    "        'env_name': 'StockPortfolioEnv',\n",
    "        'gamma': 0.99,\n",
    "        'max_minutes': 5,\n",
    "        'max_episodes': 100,\n",
    "        'goal_mean_100_reward': 1500000\n",
    "    }\n",
    "\n",
    "    policy_model_fn = lambda nS, bounds: FCDP(nS, bounds, hidden_dims=(256,256))\n",
    "    policy_max_grad_norm = float('inf')\n",
    "    policy_optimizer_fn = lambda net, lr: optim.Adam(net.parameters(), lr=lr)\n",
    "    policy_optimizer_lr = 0.001\n",
    "\n",
    "    value_model_fn = lambda nS, nA: FCQV(nS, nA, hidden_dims=(256,256))\n",
    "    value_max_grad_norm = float('inf')\n",
    "    value_optimizer_fn = lambda net, lr: optim.Adam(net.parameters(), lr=lr)\n",
    "    value_optimizer_lr = 0.001\n",
    "\n",
    "    training_strategy_fn = lambda bounds: NormalNoiseStrategy(bounds, exploration_noise_ratio=0.1)\n",
    "    evaluation_strategy_fn = lambda bounds: GreedyStrategy(bounds)\n",
    "\n",
    "    replay_buffer_fn = lambda: ReplayBuffer(max_size=50000, batch_size=128)\n",
    "    n_warmup_batches = 5\n",
    "    update_target_every_steps = 1\n",
    "    tau = 0.05\n",
    "    \n",
    "    env_name, gamma, max_minutes, \\\n",
    "    max_episodes, goal_mean_100_reward = environment_settings.values()\n",
    "\n",
    "    agent = DDPG(replay_buffer_fn,\n",
    "                 policy_model_fn, \n",
    "                 policy_max_grad_norm, \n",
    "                 policy_optimizer_fn, \n",
    "                 policy_optimizer_lr,\n",
    "                 value_model_fn, \n",
    "                 value_max_grad_norm, \n",
    "                 value_optimizer_fn, \n",
    "                 value_optimizer_lr, \n",
    "                 training_strategy_fn,\n",
    "                 evaluation_strategy_fn,\n",
    "                 n_warmup_batches,\n",
    "                 update_target_every_steps,\n",
    "                 tau)\n",
    "\n",
    "    make_env_fn, make_env_kargs = get_make_env_fn(env_name=env_name)\n",
    "    result, final_eval_score, training_time, wallclock_time = agent.train(\n",
    "        make_env_fn, make_env_kargs, seed, gamma, max_minutes, max_episodes, \n",
    "        goal_mean_100_reward)\n",
    "    ddpg_results.append(result)\n",
    "    if final_eval_score > best_eval_score:\n",
    "        best_eval_score = final_eval_score\n",
    "        best_agent = agent\n",
    "ddpg_results = np.array(ddpg_results)\n",
    "_ = BEEP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "0v7NF1rnWZAn"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ddpg_max_r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-09662bbae677>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# DDPG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddpg_max_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddpg_min_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0maxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddpg_mean_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DDPG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ddpg_max_r' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ddpg_results_backup = ddpg_results\n",
    "ddpg_results_new = []\n",
    "\n",
    "for i in range(len(ddpg_results)):\n",
    "    if not np.isnan(ddpg_results[i][-1][-1]):\n",
    "        ddpg_results_new.append(ddpg_results[i])\n",
    "\n",
    "ddpg_results_new = np.array(ddpg_results_new)\n",
    "ddpg_results = ddpg_results_new\n",
    "\n",
    "ddpg_max_t, ddpg_max_r, ddpg_max_s, \\\n",
    "ddpg_max_sec, ddpg_max_rt = np.max(ddpg_results, axis=0).T\n",
    "ddpg_min_t, ddpg_min_r, ddpg_min_s, \\\n",
    "ddpg_min_sec, ddpg_min_rt = np.min(ddpg_results, axis=0).T\n",
    "ddpg_mean_t, ddpg_mean_r, ddpg_mean_s, \\\n",
    "ddpg_mean_sec, ddpg_mean_rt = np.mean(ddpg_results, axis=0).T\n",
    "ddpg_x = np.arange(len(ddpg_mean_s))\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15,10), sharey=False, sharex=True)\n",
    "\n",
    "# DDPG\n",
    "axs[0].plot(ddpg_max_r, 'r', linewidth=1)\n",
    "axs[0].plot(ddpg_min_r, 'r', linewidth=1)\n",
    "axs[0].plot(ddpg_mean_r, 'r:', label='DDPG', linewidth=2)\n",
    "axs[0].fill_between(\n",
    "    ddpg_x, ddpg_min_r, ddpg_max_r, facecolor='r', alpha=0.3)\n",
    "\n",
    "axs[1].plot(ddpg_max_s, 'r', linewidth=1)\n",
    "axs[1].plot(ddpg_min_s, 'r', linewidth=1)\n",
    "axs[1].plot(ddpg_mean_s, 'r:', label='DDPG', linewidth=2)\n",
    "axs[1].fill_between(\n",
    "    ddpg_x, ddpg_min_s, ddpg_max_s, facecolor='r', alpha=0.3)\n",
    "\n",
    "# ALL\n",
    "axs[0].set_title('Moving Avg Reward (Training)')\n",
    "axs[1].set_title('Moving Avg Reward (Evaluation)')\n",
    "plt.xlabel('Episodes')\n",
    "axs[0].legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "YfYEm4_312Pk"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'target_policy_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-cead9fe32f5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_trade_gym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# action, _states = best_agent.predict(test_obs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_agent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_policy_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_obs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtest_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'target_policy_model'"
     ]
    }
   ],
   "source": [
    "# trading - testing\n",
    "test_env, test_obs = e_trade_gym.get_sb_env()\n",
    "\"\"\"make a prediction\"\"\"\n",
    "account_memory = []\n",
    "actions_memory = []\n",
    "test_env.reset()\n",
    "for i in range(len(e_trade_gym.df.index.unique())):\n",
    "    # action, _states = best_agent.predict(test_obs)\n",
    "    action = best_agent.target_policy_model(test_obs)\n",
    "    action = action.detach().cpu().numpy()[0]\n",
    "    test_obs, rewards, dones, info = test_env.step(action)\n",
    "    if i == (len(e_trade_gym.df.index.unique()) - 2):\n",
    "        account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "        actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "    if dones[0]:\n",
    "        print(\"hit end!\")\n",
    "        break\n",
    "\n",
    "df_daily_return = account_memory[0]\n",
    "df_actions = actions_memory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvBCRew-3DJr",
    "outputId": "aaee3407-dc77-4e93-ed00-82cca2d4cd65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Annual return          0.273901\n",
       "Cumulative returns     0.382286\n",
       "Annual volatility      0.135544\n",
       "Sharpe ratio           1.854464\n",
       "Calmar ratio           3.040856\n",
       "Stability              0.914464\n",
       "Max drawdown          -0.090074\n",
       "Omega ratio            1.363125\n",
       "Sortino ratio          2.792149\n",
       "Skew                  -0.194691\n",
       "Kurtosis               1.527521\n",
       "Tail ratio             1.091295\n",
       "Daily value at risk   -0.016079\n",
       "Alpha                  0.000000\n",
       "Beta                   1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return)\n",
    "perf_func = timeseries.perf_stats \n",
    "perf_stats_all = perf_func( returns=DRL_strat, \n",
    "                              factor_returns=DRL_strat, \n",
    "                                positions=None, transactions=None, turnover_denom=\"AGB\")\n",
    "perf_stats_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAFX0mBJ4iXm"
   },
   "source": [
    "# DDPG with multi-head self attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting einops\n",
      "  Downloading einops-0.4.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install einops\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "xgYriBwV2QpQ"
   },
   "outputs": [],
   "source": [
    "class FCQV_MHA(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 output_dim, \n",
    "                 hidden_dims=(32,32), \n",
    "                 activation_fc=F.relu,\n",
    "                 num_stock = 28,\n",
    "                 num_head = 3, \n",
    "                 num_batch = 128,\n",
    "                 num_feat = 36, # original num of features per stock\n",
    "                 node_size = 64 # num of hidden featurs for attention module\n",
    "                ):\n",
    "        super(FCQV_MHA, self).__init__()\n",
    "        self.activation_fc = activation_fc\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            in_dim = hidden_dims[i]\n",
    "            if i == 0: \n",
    "                in_dim += output_dim\n",
    "            hidden_layer = nn.Linear(in_dim, hidden_dims[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], 1)\n",
    "\n",
    "        device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda:0\"\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "\n",
    "        self.num_stock = num_stock\n",
    "        self.num_head = num_head\n",
    "        self.num_batch = num_batch\n",
    "        self.num_feat = num_feat\n",
    "        self.node_size = node_size\n",
    "        self.proj_shape = (self.num_feat, self.num_head * self.node_size)\n",
    "        self.k_proj = nn.Linear(*self.proj_shape)\n",
    "        self.q_proj = nn.Linear(*self.proj_shape)\n",
    "        self.v_proj = nn.Linear(*self.proj_shape)\n",
    "        self.node_shape = (self.num_head, self.num_stock, self.node_size)\n",
    "        self.k_norm = nn.LayerNorm(self.node_shape, elementwise_affine=True)\n",
    "        self.q_norm = nn.LayerNorm(self.node_shape, elementwise_affine=True)\n",
    "        self.v_norm = nn.LayerNorm(self.node_shape, elementwise_affine=True)\n",
    "        self.k_lin = nn.Linear(self.node_size, self.num_stock) #B\n",
    "        self.q_lin = nn.Linear(self.node_size, self.num_stock)\n",
    "        self.a_lin = nn.Linear(self.num_stock, self.num_stock)\n",
    "        \n",
    "        self.linear1 = nn.Linear(self.num_head * self.node_size, self.node_size)\n",
    "        self.norm1 = nn.LayerNorm([self.num_stock, self.node_size], elementwise_affine=False)\n",
    "        self.linear2 = nn.Linear(self.node_size, self.num_stock * self.num_feat)\n",
    "    \n",
    "    def _format(self, state, action):\n",
    "        x, u = state, action\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, \n",
    "                             device=self.device, \n",
    "                             dtype=torch.float32)\n",
    "            x = x.unsqueeze(0)\n",
    "        if not isinstance(u, torch.Tensor):\n",
    "            u = torch.tensor(u, \n",
    "                             device=self.device, \n",
    "                             dtype=torch.float32)\n",
    "            u = u.unsqueeze(0)\n",
    "        return x, u\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        x, u = self._format(state, action)\n",
    "        \n",
    "        ####### MHA #####\n",
    "#         print(x.shape)\n",
    "        x2 = x.reshape(self.num_batch, self.num_stock, -1)\n",
    "#         print(x2.shape)\n",
    "        \n",
    "        K = rearrange(self.k_proj(x2), \"b n (head d) -> b head n d\", head=self.num_head)\n",
    "        K = self.k_norm(K) \n",
    "        \n",
    "        Q = rearrange(self.q_proj(x2), \"b n (head d) -> b head n d\", head=self.num_head)\n",
    "        Q = self.q_norm(Q) \n",
    "        \n",
    "        V = rearrange(self.v_proj(x2), \"b n (head d) -> b head n d\", head=self.num_head)\n",
    "        V = self.v_norm(V) \n",
    "        \n",
    "        A = torch.nn.functional.elu(self.q_lin(Q) + self.k_lin(K)) #D\n",
    "        A = self.a_lin(A)\n",
    "        A = torch.nn.functional.softmax(A, dim=3) \n",
    "        with torch.no_grad():\n",
    "            self.att_map = A.clone() #E\n",
    "        E = torch.einsum('bhfc,bhcd->bhfd',A,V) #F\n",
    "        E = rearrange(E, 'b head n d -> b n (head d)')\n",
    "        E = self.linear1(E)\n",
    "        E = torch.relu(E)\n",
    "        E = self.norm1(E)\n",
    "        E = E.max(dim=1)[0]\n",
    "        y = self.linear2(E)\n",
    "        y = torch.nn.functional.elu(y)\n",
    "#         print(y.shape)\n",
    "        \n",
    "        x = self.activation_fc(self.input_layer(y))\n",
    "        for i, hidden_layer in enumerate(self.hidden_layers):\n",
    "            if i == 0:\n",
    "                x = torch.cat((x, u), dim=1)\n",
    "            x = self.activation_fc(hidden_layer(x))\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "    \n",
    "    def load(self, experiences):\n",
    "        states, actions, new_states, rewards, is_terminals = experiences\n",
    "        states = torch.from_numpy(states).float().to(self.device)\n",
    "        actions = torch.from_numpy(actions).float().to(self.device)\n",
    "        new_states = torch.from_numpy(new_states).float().to(self.device)\n",
    "        rewards = torch.from_numpy(rewards).float().to(self.device)\n",
    "        is_terminals = torch.from_numpy(is_terminals).float().to(self.device)\n",
    "        return states, actions, new_states, rewards, is_terminals\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "class FCDP_MHA(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim,\n",
    "                 action_bounds,\n",
    "                 hidden_dims=(32,32), \n",
    "                 activation_fc=F.relu,\n",
    "                 out_activation_fc=F.tanh):\n",
    "        super(FCDP_MHA, self).__init__()\n",
    "        self.activation_fc = activation_fc\n",
    "        self.out_activation_fc = out_activation_fc\n",
    "        self.env_min, self.env_max = action_bounds\n",
    "\n",
    "        self.input_layer = nn.Linear(input_dim, hidden_dims[0])\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(len(hidden_dims)-1):\n",
    "            hidden_layer = nn.Linear(hidden_dims[i], hidden_dims[i+1])\n",
    "            self.hidden_layers.append(hidden_layer)\n",
    "        self.output_layer = nn.Linear(hidden_dims[-1], len(self.env_max))\n",
    "\n",
    "        device = \"cpu\"\n",
    "        if torch.cuda.is_available():\n",
    "            device = \"cuda:0\"\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "        \n",
    "        self.env_min = torch.tensor(self.env_min,\n",
    "                                    device=self.device, \n",
    "                                    dtype=torch.float32)\n",
    "\n",
    "        self.env_max = torch.tensor(self.env_max,\n",
    "                                    device=self.device, \n",
    "                                    dtype=torch.float32)\n",
    "        \n",
    "        self.nn_min = self.out_activation_fc(\n",
    "            torch.Tensor([float('-inf')])).to(self.device)\n",
    "        self.nn_max = self.out_activation_fc(\n",
    "            torch.Tensor([float('inf')])).to(self.device)\n",
    "        self.rescale_fn = lambda x: (x - self.nn_min) * (self.env_max - self.env_min) / \\\n",
    "                                    (self.nn_max - self.nn_min) + self.env_min\n",
    "\n",
    "    def _format(self, state):\n",
    "        x = state\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, \n",
    "                             device=self.device, \n",
    "                             dtype=torch.float32)\n",
    "            x = x.unsqueeze(0)\n",
    "        return x\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = self._format(state)\n",
    "        # print(1)\n",
    "        # print(x.shape)\n",
    "        x = self.activation_fc(self.input_layer(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = self.activation_fc(hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        x = self.out_activation_fc(x)\n",
    "        return self.rescale_fn(x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4276531.907803205\n",
      "Sharpe:  0.7918242020928153\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "\u001b[2Kel 00:05:08, ep 0000, ts 0002893, ar 10 7563090536.3±000.0, 100 7563090536.3±000.0, ex 100 0.1±0.0, ev 7494986177.5±000.0\n",
      "--> reached_max_minutes ✕\n",
      "--> reached_goal_mean_reward ✓\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4229409.264306326\n",
      "Sharpe:  0.7889318132433587\n",
      "=================================\n",
      "Training complete.\n",
      "Final evaluation score 7494986177.53±0.00 in 303.43s training time, 791.22s wall-clock time.\n",
      "\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4996991.4468175955\n",
      "Sharpe:  0.8742684204109473\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "\u001b[2Kel 00:05:09, ep 0000, ts 0002893, ar 10 8213461765.4±000.0, 100 8213461765.4±000.0, ex 100 0.1±0.0, ev 8010276716.0±000.0\n",
      "--> reached_max_minutes ✕\n",
      "--> reached_goal_mean_reward ✓\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4904087.515806523\n",
      "Sharpe:  0.8767906560549861\n",
      "=================================\n",
      "Training complete.\n",
      "Final evaluation score 8010276716.04±0.00 in 304.99s training time, 778.40s wall-clock time.\n",
      "\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4721591.72857643\n",
      "Sharpe:  0.826853816021707\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "\u001b[2Kel 00:13:26, ep 0000, ts 0002893, ar 10 8035695416.1±000.0, 100 8035695416.1±000.0, ex 100 0.1±0.0, ev 7743894066.1±000.0\n",
      "--> reached_max_minutes ✕\n",
      "--> reached_goal_mean_reward ✓\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:4552299.5324266385\n",
      "Sharpe:  0.8141730901544064\n",
      "=================================\n",
      "Training complete.\n",
      "Final evaluation score 7743894066.13±0.00 in 800.60s training time, 1368.45s wall-clock time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings ; warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import threading\n",
    "from torch.distributions import Normal\n",
    "\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from itertools import cycle, count\n",
    "from textwrap import wrap\n",
    "\n",
    "# import pybullet_envs\n",
    "import matplotlib\n",
    "import subprocess\n",
    "import os.path\n",
    "import tempfile\n",
    "import random\n",
    "# import base64pybullet_envs\n",
    "import pprint\n",
    "import glob\n",
    "import time      \n",
    "import json\n",
    "import sys\n",
    "import gym\n",
    "import io\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from gym import wrappers\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from subprocess import check_output\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "LEAVE_PRINT_EVERY_N_SECS = 300\n",
    "ERASE_LINE = '\\x1b[2K'\n",
    "EPS = 1e-6\n",
    "BEEP = lambda: os.system(\"printf '\\a'\")\n",
    "RESULTS_DIR = os.path.join('..', 'results')\n",
    "SEEDS = [12, 34, 56]#, 78, 90, 100, 120, 150, 180, 200)\n",
    "BATCH = 128\n",
    "\n",
    "ddpg_results = []\n",
    "best_agent, best_eval_score = None, float('-inf')\n",
    "for seed in SEEDS:\n",
    "    environment_settings = {\n",
    "        'env_name': 'StockPortfolioEnv',\n",
    "        'gamma': 0.99,\n",
    "        'max_minutes': 1,\n",
    "        'max_episodes': 10,\n",
    "        'goal_mean_100_reward': 1500000\n",
    "    }\n",
    "\n",
    "    policy_model_fn = lambda nS, bounds: FCDP_MHA(nS, bounds, hidden_dims=(256,256))\n",
    "    policy_max_grad_norm = float('inf')\n",
    "    policy_optimizer_fn = lambda net, lr: optim.Adam(net.parameters(), lr=lr)\n",
    "    policy_optimizer_lr = 0.001\n",
    "\n",
    "    value_model_fn = lambda nS, nA: FCQV_MHA(nS, nA, hidden_dims=(256,256), num_stock = e_train_gym.stock_dim,\n",
    "                                                 num_head = 3, \n",
    "                                                 num_batch = BATCH,\n",
    "                                                 num_feat = e_train_gym.feat_dim, \n",
    "                                                 node_size = 64)\n",
    "    value_max_grad_norm = float('inf')\n",
    "    value_optimizer_fn = lambda net, lr: optim.Adam(net.parameters(), lr=lr)\n",
    "    value_optimizer_lr = 0.001\n",
    "\n",
    "    training_strategy_fn = lambda bounds: NormalNoiseStrategy(bounds, exploration_noise_ratio=0.1)\n",
    "    evaluation_strategy_fn = lambda bounds: GreedyStrategy(bounds)\n",
    "\n",
    "    replay_buffer_fn = lambda: ReplayBuffer(max_size=50000, batch_size=BATCH)\n",
    "    n_warmup_batches = 5\n",
    "    update_target_every_steps = 1\n",
    "    tau = 0.05\n",
    "    \n",
    "    env_name, gamma, max_minutes, \\\n",
    "    max_episodes, goal_mean_100_reward = environment_settings.values()\n",
    "\n",
    "    agent = DDPG(replay_buffer_fn,\n",
    "                 policy_model_fn, \n",
    "                 policy_max_grad_norm, \n",
    "                 policy_optimizer_fn, \n",
    "                 policy_optimizer_lr,\n",
    "                 value_model_fn, \n",
    "                 value_max_grad_norm, \n",
    "                 value_optimizer_fn, \n",
    "                 value_optimizer_lr, \n",
    "                 training_strategy_fn,\n",
    "                 evaluation_strategy_fn,\n",
    "                 n_warmup_batches,\n",
    "                 update_target_every_steps,\n",
    "                 tau)\n",
    "\n",
    "    make_env_fn, make_env_kargs = get_make_env_fn(env_name=env_name)\n",
    "    result, final_eval_score, training_time, wallclock_time = agent.train(\n",
    "        make_env_fn, make_env_kargs, seed, gamma, max_minutes, max_episodes, \n",
    "        goal_mean_100_reward)\n",
    "    ddpg_results.append(result)\n",
    "    if final_eval_score > best_eval_score:\n",
    "        best_eval_score = final_eval_score\n",
    "        best_agent = agent\n",
    "ddpg_results = np.array(ddpg_results)\n",
    "_ = BEEP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LhFmpGblOBTO",
    "outputId": "800e9d4a-b498-4137-95ed-e241761a6af4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = e_train_gym.reset()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KhO34OUAOmJt"
   },
   "source": [
    "# a.reshape(28,-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "4-8Fvu-7QqnD"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_train_gym.feat_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Using cached torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DDPG' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-d85db699708d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install torchsummary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1008\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# register hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DDPG' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "# !pip install torchsummary\n",
    "# from torchsummary import summary\n",
    "# summary(agent, input_size=(1008,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\n",
      "begin_total_asset:1000000\n",
      "end_total_asset:1378897.8163025288\n",
      "Sharpe:  1.9277075762062084\n",
      "=================================\n",
      "hit end!\n"
     ]
    }
   ],
   "source": [
    "# trading - testing\n",
    "test_env, test_obs = e_trade_gym.get_sb_env()\n",
    "\"\"\"make a prediction\"\"\"\n",
    "account_memory = []\n",
    "actions_memory = []\n",
    "test_env.reset()\n",
    "for i in range(len(e_trade_gym.df.index.unique())):\n",
    "    # action, _states = best_agent.predict(test_obs)\n",
    "    action = best_agent.target_policy_model(test_obs)\n",
    "    action = action.detach().cpu().numpy()[0]\n",
    "    test_obs, rewards, dones, info = test_env.step(action)\n",
    "    if i == (len(e_trade_gym.df.index.unique()) - 2):\n",
    "        account_memory = test_env.env_method(method_name=\"save_asset_memory\")\n",
    "        actions_memory = test_env.env_method(method_name=\"save_action_memory\")\n",
    "    if dones[0]:\n",
    "        print(\"hit end!\")\n",
    "        break\n",
    "\n",
    "df_daily_return = account_memory[0]\n",
    "df_actions = actions_memory[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation maximum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-d87e2f737548>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mddpg_max_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddpg_max_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddpg_max_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mddpg_max_sec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddpg_max_rt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddpg_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mddpg_min_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddpg_min_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddpg_min_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mddpg_min_sec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddpg_min_rt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddpg_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/py37/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation maximum which has no identity"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ddpg_results_backup = ddpg_results\n",
    "ddpg_results_new = []\n",
    "\n",
    "for i in range(len(ddpg_results)):\n",
    "    if not np.isnan(ddpg_results[i][-1][-1]):\n",
    "        ddpg_results_new.append(ddpg_results[i])\n",
    "\n",
    "ddpg_results_new = np.array(ddpg_results_new)\n",
    "ddpg_results = ddpg_results_new\n",
    "\n",
    "ddpg_max_t, ddpg_max_r, ddpg_max_s, \\\n",
    "ddpg_max_sec, ddpg_max_rt = np.max(ddpg_results, axis=0).T\n",
    "ddpg_min_t, ddpg_min_r, ddpg_min_s, \\\n",
    "ddpg_min_sec, ddpg_min_rt = np.min(ddpg_results, axis=0).T\n",
    "ddpg_mean_t, ddpg_mean_r, ddpg_mean_s, \\\n",
    "ddpg_mean_sec, ddpg_mean_rt = np.mean(ddpg_results, axis=0).T\n",
    "ddpg_x = np.arange(len(ddpg_mean_s))\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(15,10), sharey=False, sharex=True)\n",
    "\n",
    "# DDPG\n",
    "axs[0].plot(ddpg_max_r, 'r', linewidth=1)\n",
    "axs[0].plot(ddpg_min_r, 'r', linewidth=1)\n",
    "axs[0].plot(ddpg_mean_r, 'r:', label='DDPG', linewidth=2)\n",
    "axs[0].fill_between(\n",
    "    ddpg_x, ddpg_min_r, ddpg_max_r, facecolor='r', alpha=0.3)\n",
    "\n",
    "axs[1].plot(ddpg_max_s, 'r', linewidth=1)\n",
    "axs[1].plot(ddpg_min_s, 'r', linewidth=1)\n",
    "axs[1].plot(ddpg_mean_s, 'r:', label='DDPG', linewidth=2)\n",
    "axs[1].fill_between(\n",
    "    ddpg_x, ddpg_min_s, ddpg_max_s, facecolor='r', alpha=0.3)\n",
    "\n",
    "# ALL\n",
    "axs[0].set_title('Moving Avg Reward (Training)')\n",
    "axs[1].set_title('Moving Avg Reward (Evaluation)')\n",
    "plt.xlabel('Episodes')\n",
    "axs[0].legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2.89300000e+03, 7.56309054e+09, 7.49498618e+09, 3.03426240e+02,\n",
       "         3.08285057e+02],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan]],\n",
       "\n",
       "       [[2.89300000e+03, 8.21346177e+09, 8.01027672e+09, 3.04993802e+02,\n",
       "         3.09615970e+02],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan]],\n",
       "\n",
       "       [[2.89300000e+03, 8.03569542e+09, 7.74389407e+09, 8.00599280e+02,\n",
       "         8.06104655e+02],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan],\n",
       "        [           nan,            nan,            nan,            nan,\n",
       "                    nan]]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddpg_results_backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Portfolio allocation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
